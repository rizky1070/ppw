{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing email"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data from berita_cnn.csv\n",
        "df = pd.read_csv('spam.csv', encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (5572, 5)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Text</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>5568</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>5569</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>5570</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>5571</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>5572</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                               Text Unnamed: 2  \\\n",
              "0        1  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1        2                      Ok lar... Joking wif u oni...        NaN   \n",
              "2        3  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3        4  U dun say so early hor... U c already then say...        NaN   \n",
              "4        5  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "...    ...                                                ...        ...   \n",
              "5567  5568  This is the 2nd time we have tried 2 contact u...        NaN   \n",
              "5568  5569              Will Ì_ b going to esplanade fr home?        NaN   \n",
              "5569  5570  Pity, * was in mood for that. So...any other s...        NaN   \n",
              "5570  5571  The guy did some bitching but I acted like i'd...        NaN   \n",
              "5571  5572                         Rofl. Its true to its name        NaN   \n",
              "\n",
              "     Unnamed: 3 Unnamed: 4  \n",
              "0           NaN        NaN  \n",
              "1           NaN        NaN  \n",
              "2           NaN        NaN  \n",
              "3           NaN        NaN  \n",
              "4           NaN        NaN  \n",
              "...         ...        ...  \n",
              "5567        NaN        NaN  \n",
              "5568        NaN        NaN  \n",
              "5569        NaN        NaN  \n",
              "5570        NaN        NaN  \n",
              "5571        NaN        NaN  \n",
              "\n",
              "[5572 rows x 5 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display basic information about the dataset\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   id          5572 non-null   int64 \n",
            " 1   Text        5572 non-null   object\n",
            " 2   Unnamed: 2  50 non-null     object\n",
            " 3   Unnamed: 3  12 non-null     object\n",
            " 4   Unnamed: 4  6 non-null      object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 217.8+ KB\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDataset info:\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#   PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       Go until jurong point, crazy.. Available only ...\n",
              "1                           Ok lar... Joking wif u oni...\n",
              "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3       U dun say so early hor... U c already then say...\n",
              "4       Nah I don't think he goes to usf, he lives aro...\n",
              "                              ...                        \n",
              "5567    This is the 2nd time we have tried 2 contact u...\n",
              "5568                Will Ì_ b going to esplanade fr home?\n",
              "5569    Pity, * was in mood for that. So...any other s...\n",
              "5570    The guy did some bitching but I acted like i'd...\n",
              "5571                           Rofl. Its true to its name\n",
              "Name: Text, Length: 5572, dtype: object"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tampilkan data \"isi\"\n",
        "df['Text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hapus Missing Value dan Data Duplicat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hapus baris dengan Missing Value di 'berita'\n",
        "df.dropna(subset=['Text'], inplace=True)\n",
        "\n",
        "# Hapus data duplikat\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>cleaned_isi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  \\\n",
              "0  Go until jurong point, crazy.. Available only ...   \n",
              "1                      Ok lar... Joking wif u oni...   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3  U dun say so early hor... U c already then say...   \n",
              "4  Nah I don't think he goes to usf, he lives aro...   \n",
              "\n",
              "                                         cleaned_isi  \n",
              "0  go until jurong point crazy available only in ...  \n",
              "1                            ok lar joking wif u oni  \n",
              "2  free entry in a wkly comp to win fa cup final ...  \n",
              "3        u dun say so early hor u c already then say  \n",
              "4  nah i dont think he goes to usf he lives aroun...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Fungsi untuk membersihkan teks\n",
        "def clean_text(text):\n",
        "    # Pastikan input adalah string\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "        \n",
        "    text = text.lower() # 1. Ubah ke huruf kecil\n",
        "    \n",
        "    # 2. Ganti karakter non-breaking space (U+00A0) dengan spasi biasa\n",
        "    text = text.replace(u'\\xa0', u' ')\n",
        "    \n",
        "    # 3. Hapus awalan kota dan sumber berita \n",
        "    # Pola: NAMA_KOTA,BANGSAONLINE.COM-\n",
        "    text = re.sub(r'^\\w+\\s*,\\s*bangsaonline\\.com[–-]?\\s*', '', text)\n",
        "    \n",
        "    # 4. Hapus semua karakter yang BUKAN huruf, angka, atau spasi\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    \n",
        "    # 5. Hapus semua angka\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    \n",
        "    # 6. Ganti spasi ganda/lebih menjadi satu spasi & hapus spasi di awal/akhir\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Terapkan pembersihan ke kolom 'isi'\n",
        "df['cleaned_isi'] = df['Text'].apply(clean_text)\n",
        "\n",
        "# Tampilkan DataFrame\n",
        "display(df[['Text', 'cleaned_isi']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenisasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\rizky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
            "Requirement already satisfied: click in c:\\users\\rizky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in c:\\users\\rizky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rizky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2025.9.18)\n",
            "Requirement already satisfied: tqdm in c:\\users\\rizky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\rizky\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "# Perintah untuk menginstal library menggunakan path Python yang sedang aktif\n",
        "!{sys.executable} -m pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Rizky\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\Rizky\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_isi</th>\n",
              "      <th>tokenized_isi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
              "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         cleaned_isi  \\\n",
              "0  go until jurong point crazy available only in ...   \n",
              "1                            ok lar joking wif u oni   \n",
              "2  free entry in a wkly comp to win fa cup final ...   \n",
              "3        u dun say so early hor u c already then say   \n",
              "4  nah i dont think he goes to usf he lives aroun...   \n",
              "\n",
              "                                       tokenized_isi  \n",
              "0  [go, until, jurong, point, crazy, available, o...  \n",
              "1                     [ok, lar, joking, wif, u, oni]  \n",
              "2  [free, entry, in, a, wkly, comp, to, win, fa, ...  \n",
              "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
              "4  [nah, i, dont, think, he, goes, to, usf, he, l...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') \n",
        "\n",
        "# Fungsi untuk melakukan tokenisasi\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Terapkan tokenisasi ke kolom 'cleaned_isi'\n",
        "df['tokenized_isi'] = df['cleaned_isi'].apply(tokenize_text)\n",
        "\n",
        "# Tampilkan DataFrame dengan kolom hasil tokenisasi\n",
        "display(df[['cleaned_isi', 'tokenized_isi']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stopword Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Rizky\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokenized_isi</th>\n",
              "      <th>stopwords_removed_isi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
              "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
              "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       tokenized_isi  \\\n",
              "0  [go, until, jurong, point, crazy, available, o...   \n",
              "1                     [ok, lar, joking, wif, u, oni]   \n",
              "2  [free, entry, in, a, wkly, comp, to, win, fa, ...   \n",
              "3  [u, dun, say, so, early, hor, u, c, already, t...   \n",
              "4  [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
              "\n",
              "                               stopwords_removed_isi  \n",
              "0  [go, jurong, point, crazy, available, bugis, n...  \n",
              "1                     [ok, lar, joking, wif, u, oni]  \n",
              "2  [free, entry, wkly, comp, win, fa, cup, final,...  \n",
              "3      [u, dun, say, early, hor, u, c, already, say]  \n",
              "4  [nah, dont, think, goes, usf, lives, around, t...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Dapatkan Stop Word bahasa Indonesia\n",
        "list_stopwords = set(stopwords.words('english'))\n",
        "\n",
        "# Fungsi untuk menghapus stop words\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in list_stopwords]\n",
        "\n",
        "# Terapkan penghapusan Stop Word ke kolom 'tokenized_isi'\n",
        "df['stopwords_removed_isi'] = df['tokenized_isi'].apply(remove_stopwords)\n",
        "\n",
        "# Tampilkan DataFrame\n",
        "display(df[['tokenized_isi', 'stopwords_removed_isi']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Most Frequent Words (Without Stemming):\n",
            "u: 1143\n",
            "call: 578\n",
            "im: 464\n",
            "get: 390\n",
            "ur: 384\n",
            "go: 282\n",
            "dont: 279\n",
            "free: 278\n",
            "ok: 277\n",
            "ltgt: 276\n",
            "å: 274\n",
            "know: 257\n",
            "got: 251\n",
            "like: 242\n",
            "ill: 237\n",
            "good: 234\n",
            "come: 226\n",
            "day: 211\n",
            "time: 208\n",
            "love: 195\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Gabungkan semua token setelah stopword removal menjadi satu daftar\n",
        "all_words_after_stopwords = [word for tokens in df['stopwords_removed_isi'] for word in tokens]\n",
        "\n",
        "# Hitung frekuensi setiap kata\n",
        "word_frequencies = Counter(all_words_after_stopwords)\n",
        "\n",
        "# Menampilkan kata-kata yang paling umum dan frekuensinya\n",
        "print(\"Top Most Frequent Words (Without Stemming):\")\n",
        "for word, frequency in word_frequencies.most_common(20): # Menampilkan 20 kata teratas\n",
        "    print(f\"{word}: {frequency}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hasil preprocessing disimpan di 'hasil_preprocessing_emailUTS.csv'\n",
            "Frekuensi kata disimpan di 'frekuensi_kata_emailUTS.csv'\n"
          ]
        }
      ],
      "source": [
        "# Buat DataFrame baru dengan isi berita asli, hasil preprocessing, dan kategori\n",
        "processed_df = df[['Text', 'stopwords_removed_isi']].copy()\n",
        "\n",
        "# Ganti nama kolom 'stopwords_removed_isi' menjadi 'hasil_preprocessing'\n",
        "processed_df.rename(columns={'stopwords_removed_isi': 'hasil_preprocessing'}, inplace=True)\n",
        "\n",
        "# Konversi frekuensi kata ke DataFrame\n",
        "frequency_df = pd.DataFrame.from_dict(word_frequencies, orient='index', columns=['frequency'])\n",
        "frequency_df.index.name = 'word'\n",
        "frequency_df.sort_values(by='frequency', ascending=False, inplace=True)\n",
        "\n",
        "# Simpan ke dua file CSV terpisah\n",
        "processed_df.to_csv('hasil_preprocessing_emailUTS.csv', index=False, encoding='utf-8')\n",
        "frequency_df.to_csv('frekuensi_kata_emailUTS.csv', encoding='utf-8')\n",
        "\n",
        "print(\"Hasil preprocessing disimpan di 'hasil_preprocessing_emailUTS.csv'\")\n",
        "print(\"Frekuensi kata disimpan di 'frekuensi_kata_emailUTS.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>hasil_preprocessing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>['go', 'jurong', 'point', 'crazy', 'available'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>['ok', 'lar', 'joking', 'wif', 'u', 'oni']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>['free', 'entry', 'wkly', 'comp', 'win', 'fa',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>['u', 'dun', 'say', 'early', 'hor', 'u', 'c', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>['nah', 'dont', 'think', 'goes', 'usf', 'lives...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>['nd', 'time', 'tried', 'contact', 'u', 'u', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>['ì_', 'b', 'going', 'esplanade', 'fr', 'home']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>['pity', 'mood', 'soany', 'suggestions']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>['guy', 'bitching', 'acted', 'like', 'id', 'in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>['rofl', 'true', 'name']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  \\\n",
              "0     Go until jurong point, crazy.. Available only ...   \n",
              "1                         Ok lar... Joking wif u oni...   \n",
              "2     Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3     U dun say so early hor... U c already then say...   \n",
              "4     Nah I don't think he goes to usf, he lives aro...   \n",
              "...                                                 ...   \n",
              "5567  This is the 2nd time we have tried 2 contact u...   \n",
              "5568              Will Ì_ b going to esplanade fr home?   \n",
              "5569  Pity, * was in mood for that. So...any other s...   \n",
              "5570  The guy did some bitching but I acted like i'd...   \n",
              "5571                         Rofl. Its true to its name   \n",
              "\n",
              "                                    hasil_preprocessing  \n",
              "0     ['go', 'jurong', 'point', 'crazy', 'available'...  \n",
              "1            ['ok', 'lar', 'joking', 'wif', 'u', 'oni']  \n",
              "2     ['free', 'entry', 'wkly', 'comp', 'win', 'fa',...  \n",
              "3     ['u', 'dun', 'say', 'early', 'hor', 'u', 'c', ...  \n",
              "4     ['nah', 'dont', 'think', 'goes', 'usf', 'lives...  \n",
              "...                                                 ...  \n",
              "5567  ['nd', 'time', 'tried', 'contact', 'u', 'u', '...  \n",
              "5568    ['ì_', 'b', 'going', 'esplanade', 'fr', 'home']  \n",
              "5569           ['pity', 'mood', 'soany', 'suggestions']  \n",
              "5570  ['guy', 'bitching', 'acted', 'like', 'id', 'in...  \n",
              "5571                           ['rofl', 'true', 'name']  \n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasil_preprocessing = \"hasil_preprocessing_emailUTS.csv\"  \n",
        "df = pd.read_csv(hasil_preprocessing)\n",
        "\n",
        "# Tampilkan data\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u</td>\n",
              "      <td>1143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>call</td>\n",
              "      <td>578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im</td>\n",
              "      <td>464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get</td>\n",
              "      <td>390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ur</td>\n",
              "      <td>384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8479</th>\n",
              "      <td>practising</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8480</th>\n",
              "      <td>rupaul</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8481</th>\n",
              "      <td>baskets</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8482</th>\n",
              "      <td>dane</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8483</th>\n",
              "      <td>bitching</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8484 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            word  frequency\n",
              "0              u       1143\n",
              "1           call        578\n",
              "2             im        464\n",
              "3            get        390\n",
              "4             ur        384\n",
              "...          ...        ...\n",
              "8479  practising          1\n",
              "8480      rupaul          1\n",
              "8481     baskets          1\n",
              "8482        dane          1\n",
              "8483    bitching          1\n",
              "\n",
              "[8484 rows x 2 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frekuensi_kata = \"frekuensi_kata_emailUTS.csv\"  \n",
        "df = pd.read_csv(frekuensi_kata)\n",
        "\n",
        "# Tampilkan data\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
