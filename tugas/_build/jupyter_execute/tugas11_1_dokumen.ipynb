{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dokumen Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7moTcKeJf_n",
    "outputId": "587911d8-3648-453c-f398-24ebb2691e05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf4llm in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: nltk in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: networkx in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: numpy in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pymupdf>=1.26.6 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from pymupdf4llm) (1.26.7)\n",
      "Requirement already satisfied: tabulate in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from pymupdf4llm) (0.9.0)\n",
      "Requirement already satisfied: click in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rizky\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rizky\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rizky\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rizky\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\laragon\\bin\\python\\python-3.10\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf4llm nltk networkx matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GV36hU9-JEcc",
    "outputId": "04d3a323-84e6-4936-bb5a-e5aaa979c1bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using the pymupdf_layout package for a greatly improved page layout analysis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rizky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rizky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Rizky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Mengekstrak teks dari Nasi_goreng_food_and_wine_pairing_Fried_rice_food_.pdf ---\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "no such file: 'Nasi_goreng_food_and_wine_pairing_Fried_rice_food_.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32548\\2940036121.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Full Word Graph ({num_nodes} words)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32548\\2940036121.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# ==========================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# TAHAP 1: Ekstrak Text dari PDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# ==========================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"--- 1. Mengekstrak teks dari {pdf_path} ---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mtext_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Berhasil mengekstrak {len(text_content)} karakter.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# ==========================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32548\\2940036121.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \"\"\"\n\u001b[0;32m    101\u001b[0m     \u001b[0mEkstrak\u001b[0m \u001b[0mteks\u001b[0m \u001b[0mmentah\u001b[0m \u001b[0mdari\u001b[0m \u001b[0mPDF\u001b[0m \u001b[0mmenggunakan\u001b[0m \u001b[0mPyMuPDF\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfitz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0mDiperbarui\u001b[0m \u001b[0muntuk\u001b[0m \u001b[0mmenggunakan\u001b[0m \u001b[0mpymupdf4llm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_markdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpymupdf4llm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_markdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\pymupdf\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[0;32m   3061\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count_pdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3062\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3063\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count_fz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m             \u001b[0mJM_mupdf_show_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJM_mupdf_show_errors_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: no such file: 'Nasi_goreng_food_and_wine_pairing_Fried_rice_food_.pdf'"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import nltk\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import pymupdf4llm\n",
    "import pandas as pd # Import pandas for matrix display\n",
    "import numpy as np # Import numpy\n",
    "\n",
    "# --- Konfigurasi Awal ---\n",
    "# Mengunduh resource NLTK yang diperlukan\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def main():\n",
    "    pdf_path = \"Nasi_goreng_food_and_wine_pairing_Fried_rice_food_.pdf\"\n",
    "\n",
    "    # ==========================================\n",
    "    # TAHAP 1: Ekstrak Text dari PDF\n",
    "    # ==========================================\n",
    "    print(f\"--- 1. Mengekstrak teks dari {pdf_path} ---\")\n",
    "    text_content = extract_text_from_pdf(pdf_path)\n",
    "    print(f\"Berhasil mengekstrak {len(text_content)} karakter.\")\n",
    "\n",
    "    # ==========================================\n",
    "    # TAHAP 2: Ekstrak Kalimat menggunakan NLTK\n",
    "    # ==========================================\n",
    "    print(\"\\n--- 2. Mengekstrak kalimat & Preprocessing ---\")\n",
    "    sentences = sent_tokenize(text_content)\n",
    "    print(f\"Ditemukan {len(sentences)} kalimat mentah.\")\n",
    "\n",
    "    # Tambahan: Menampilkan beberapa kalimat asli\n",
    "    print(\"\\nContoh 5 Kalimat Asli:\")\n",
    "    for i, sentence in enumerate(sentences[:5]):\n",
    "        print(f\"  {i+1}. {sentence.strip()}\")\n",
    "\n",
    "    # Preprocessing (Membersihkan teks untuk hasil graph yang lebih baik)\n",
    "    # Kita menghapus stopwords (kata umum seperti 'dan', 'yang', 'the')\n",
    "    clean_sentences_tokens = preprocess_text(sentences)\n",
    "    print(f\"Ditemukan {len(clean_sentences_tokens)} kalimat setelah preprocessing.\")\n",
    "\n",
    "    # Tambahan: Menampilkan beberapa kalimat hasil tokenisasi\n",
    "    print(\"\\nContoh 5 Kalimat Hasil Tokenisasi (setelah Preprocessing):\")\n",
    "    for i, tokens in enumerate(clean_sentences_tokens[:5]):\n",
    "        print(f\"  {i+1}. {' '.join(tokens)}\")\n",
    "\n",
    "    # ==========================================\n",
    "    # TAHAP 3: Membuat Graph menggunakan Co-occurrence Matrix\n",
    "    # ==========================================\n",
    "    print(\"\\n--- 3. Membangun Word Graph (Co-occurrence) ---\")\n",
    "    # Menggunakan Window Size = 2\n",
    "    window_size = 2\n",
    "    G = build_co_occurrence_graph(clean_sentences_tokens, window_size)\n",
    "    print(f\"Graph terbentuk dengan {G.number_of_nodes()} node (kata) dan {G.number_of_edges()} edge (hubungan).\")\n",
    "\n",
    "    print(\"\\nContoh 10 Pasangan Kata Co-occurrence Teratas:\")\n",
    "    # Mengurutkan edge berdasarkan weight (co-occurrence count) secara menurun\n",
    "    sorted_edges = sorted(G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)\n",
    "    for i, (u, v, data) in enumerate(sorted_edges[:10]):\n",
    "        print(f\"  {i+1}. ('{u}', '{v}'): {data['weight']} kali\")\n",
    "\n",
    "    # ==========================================\n",
    "    # TAHAP 4: Analisa PageRank\n",
    "    # ==========================================\n",
    "    print(\"\\n--- 4. Menghitung PageRank ---\")\n",
    "    pagerank_scores = nx.pagerank(G, weight='weight')\n",
    "\n",
    "    # Mengurutkan kata berdasarkan skor tertinggi\n",
    "    sorted_ranking = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\\nTop 10 Kata Kunci (Berdasarkan PageRank):\")\n",
    "    for i, (word, score) in enumerate(sorted_ranking[:10], 1):\n",
    "        print(f\"{i}. {word}: {score:.4f}\")\n",
    "\n",
    "    # ==========================================\n",
    "    # MENAMPILKAN CO-OCCURRENCE MATRIX\n",
    "    # ==========================================\n",
    "    print(\"\\n--- Full Co-occurrence Matrix ---\")\n",
    "    all_words_for_matrix = list(G.nodes())\n",
    "    co_occurrence_matrix = pd.DataFrame(0, index=all_words_for_matrix, columns=all_words_for_matrix, dtype=int)\n",
    "\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        co_occurrence_matrix.loc[u, v] = data['weight']\n",
    "        co_occurrence_matrix.loc[v, u] = data['weight'] # Matriks simetris\n",
    "    display(co_occurrence_matrix)\n",
    "\n",
    "\n",
    "    # ==========================================\n",
    "    # VISUALISASI\n",
    "    # ==========================================\n",
    "    visualize_graph(G)\n",
    "\n",
    "# --- Fungsi Pendukung ---\n",
    "\n",
    "def extract_text_from_pdf(filepath):\n",
    "    \"\"\"\n",
    "    Ekstrak teks mentah dari PDF menggunakan PyMuPDF (fitz).\n",
    "    Diperbarui untuk menggunakan pymupdf4llm.to_markdown().\n",
    "    \"\"\"\n",
    "    doc = fitz.open(filepath)\n",
    "    text = pymupdf4llm.to_markdown(doc)\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "def preprocess_text(sentences):\n",
    "    \"\"\"\n",
    "    Membersihkan kalimat: lowercase, hapus tanda baca, hapus stopwords.\n",
    "    \"\"\"\n",
    "    cleaned_tokens_list = []\n",
    "\n",
    "    # Gabungan stopword Indonesia dan Inggris karena dokumen bilingual\n",
    "    stop_words = set(stopwords.words('indonesian') + stopwords.words('english'))\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Hapus karakter non-huruf dan ubah ke huruf kecil\n",
    "        sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence).lower()\n",
    "        tokens = word_tokenize(sentence)\n",
    "\n",
    "        # Filter stopwords dan kata pendek\n",
    "        filtered_tokens = [w for w in tokens if w not in stop_words and len(w) > 2]\n",
    "\n",
    "        if filtered_tokens:\n",
    "            cleaned_tokens_list.append(filtered_tokens)\n",
    "\n",
    "    return cleaned_tokens_list\n",
    "\n",
    "def build_co_occurrence_graph(tokens_list, window_size=2):\n",
    "    \"\"\"\n",
    "    Membangun Graph dari co-occurrence matrix.\n",
    "    Node = Kata, Edge = Kemunculan bersama dalam window size.\n",
    "    \"\"\"\n",
    "    d = defaultdict(int)\n",
    "    vocab = set()\n",
    "\n",
    "    for tokens in tokens_list:\n",
    "        for i in range(len(tokens)):\n",
    "            token = tokens[i]\n",
    "            vocab.add(token)\n",
    "\n",
    "            for j in range(1, window_size + 1):\n",
    "                if i + j < len(tokens):\n",
    "                    next_token = tokens[i + j]\n",
    "                    # Urutkan pasangan agar (A, B) sama dengan (B, A) (Undirected Graph)\n",
    "                    pair = tuple(sorted((token, next_token)))\n",
    "                    d[pair] += 1\n",
    "\n",
    "    # Buat Graph menggunakan NetworkX\n",
    "    G = nx.Graph()\n",
    "    for (w1, w2), count in d.items():\n",
    "        G.add_edge(w1, w2, weight=count)\n",
    "\n",
    "    return G\n",
    "\n",
    "def visualize_graph(G, top_nodes_data=None):\n",
    "    plt.figure(figsize=(15, 15))  # 1. Perbesar ukuran kanvas\n",
    "\n",
    "    graph_to_draw = G\n",
    "\n",
    "    # Cek statistik graph\n",
    "    num_nodes = graph_to_draw.number_of_nodes()\n",
    "    num_edges = graph_to_draw.number_of_edges()\n",
    "    print(f\"Menampilkan Graph: {num_nodes} node, {num_edges} edge\")\n",
    "\n",
    "    if num_edges == 0:\n",
    "        print(\"PERINGATAN: Graph tidak memiliki garis penghubung!\")\n",
    "        return\n",
    "\n",
    "    # 2. Atur tata letak (Layout)\n",
    "    # k=0.5 memberikan jarak yang cukup antar node (semakin kecil k, semakin rapat)\n",
    "    pos = nx.spring_layout(graph_to_draw, k=0.5, iterations=50, seed=42)\n",
    "\n",
    "    # 3. Tentukan ukuran node berdasarkan jumlah kata\n",
    "    # Jika kata sedikit (<50), node besar (1000). Jika banyak, node kecil (100-300).\n",
    "    dynamic_node_size = 300 if num_nodes > 50 else 1000\n",
    "    dynamic_font_size = 8 if num_nodes > 50 else 10\n",
    "\n",
    "    # Gambar Nodes\n",
    "    nx.draw_networkx_nodes(graph_to_draw, pos, node_size=dynamic_node_size, node_color='lightgreen', alpha=0.9)\n",
    "\n",
    "    # Gambar Edges (Garis)\n",
    "    # width=1.0 agar garis jelas, alpha=0.6 agar tidak terlalu pekat jika tumpang tindih\n",
    "    nx.draw_networkx_edges(graph_to_draw, pos, width=1.0, alpha=0.6, edge_color='gray')\n",
    "\n",
    "    # Gambar Label\n",
    "    nx.draw_networkx_labels(graph_to_draw, pos, font_size=dynamic_font_size)\n",
    "\n",
    "    plt.title(f\"Full Word Graph ({num_nodes} words)\", fontsize=15)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}