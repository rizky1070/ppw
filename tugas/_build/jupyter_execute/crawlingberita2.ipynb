{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085e27af",
   "metadata": {},
   "source": [
    "# Crawling Berita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb1f771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencari kategori berita di bangsaonline.com...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ditemukan 37 kategori berita valid.\n",
      "\n",
      "--- Scraping Kategori: JATIM ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Masjid Nurul Hikmah Bangkalan Dibangun, Laskar Kamil Siap Ka...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Ratusan Guru Non ASN di Kediri Terima Bantuan Modal Usaha da...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM METRO ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Permudah Warga Urus Surat Secara Digital, Pemdes Banjarsari ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Fesyar 2025 Siap Digelar di Surabaya, Gubernur Khofifah Opti...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM TENGAH ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Wali Kota Kediri dan Staf Ahli Bidang Ekonomi Maritim Kemenk...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Dukung Ketahanan Pangan Nasional, Imigrasi Kediri Tanam 200 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM UTARA ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Bermekaran, Bunga Tabebuya Percantik Jalan Perkotaan di Bojo...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Seleksi Sekda Bojonegoro Resmi Dibuka, ASN Berkesempatan Daf...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM SELATAN ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Dinding Penahan Jalan Sidoutomo-Jatirejoyoso Rampung...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Perkuat Sinergi Optimalisasi PAD, Pemkot Luncuran aplikasi S...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM TIMUR ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Gandeng Ojol, Satlantas Polres Pasuruan Gelar Donor Darah di...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Jangkau 22 Ribu Penerima, Pemkab Jember Salurkan Honor Guru ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM BARAT ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: FKTP Jadi Garda Terdepan JKN, BPJS Kesehatan Dorong Edukasi ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 149\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# --- Untuk Menjalankan Seluruh Proses Scraping ---\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     df_hasil \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_semua_berita\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df_hasil \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m         pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 91\u001b[0m, in \u001b[0;36mscrape_semua_berita\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m scraped_links\u001b[38;5;241m.\u001b[39madd(link)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m     resp_detail \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     resp_detail\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     93\u001b[0m     soup_detail \u001b[38;5;241m=\u001b[39m BeautifulSoup(resp_detail\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\requests\\adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1093\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\urllib3\\connection.py:753\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    752\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 753\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m    755\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\urllib3\\connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "def dapatkan_kategori_berita():\n",
    "    \"\"\"\n",
    "    Fungsi untuk mengambil daftar semua kategori berita dari menu navigasi\n",
    "    website bangsaonline.com.\n",
    "    \"\"\"\n",
    "    print(\"Mencari kategori berita di bangsaonline.com...\")\n",
    "    kategori_list = {}\n",
    "    url_home = \"https://bangsaonline.com/\"\n",
    "    try:\n",
    "        response = requests.get(url_home, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        nav_menu = soup.select_one('ul#nav')\n",
    "        if not nav_menu:\n",
    "            print(\"Menu navigasi (ul#nav) tidak ditemukan.\")\n",
    "            return {}\n",
    "\n",
    "        for item in nav_menu.find_all(\"a\"):\n",
    "            href = item.get(\"href\")\n",
    "            nama_kategori = item.get_text(strip=True)\n",
    "            \n",
    "            if href and nama_kategori:\n",
    "                path_parts = urlparse(href).path.strip(\"/\").split(\"/\")\n",
    "                \n",
    "                if len(path_parts) == 2 and path_parts[0] == 'kanal':\n",
    "                    url_lengkap = urljoin(url_home, href)\n",
    "                    if nama_kategori not in kategori_list:\n",
    "                        kategori_list[nama_kategori] = url_lengkap\n",
    "\n",
    "        print(f\"Ditemukan {len(kategori_list)} kategori berita valid.\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Gagal mengambil daftar kategori berita: {e}\")\n",
    "        \n",
    "    return kategori_list\n",
    "\n",
    "def scrape_semua_berita():\n",
    "    \"\"\"\n",
    "    Fungsi utama untuk melakukan scraping berita dari semua kategori yang ditemukan.\n",
    "    \"\"\"\n",
    "    daftar_kategori = dapatkan_kategori_berita()\n",
    "\n",
    "    if not daftar_kategori:\n",
    "        print(\"Tidak ada kategori yang bisa di-scrape. Program berhenti.\")\n",
    "        return\n",
    "\n",
    "    data_berita = []\n",
    "    scraped_links = set()\n",
    "    url_home = \"https://bangsaonline.com/\"\n",
    "\n",
    "    for nama_kategori, url_kategori in daftar_kategori.items():\n",
    "        print(f\"\\n--- Scraping Kategori: {nama_kategori.upper()} ---\")\n",
    "        artikel_diambil = 0\n",
    "        \n",
    "        try:\n",
    "            response_kategori = requests.get(url_kategori, timeout=10)\n",
    "            response_kategori.raise_for_status()\n",
    "            soup_kategori = BeautifulSoup(response_kategori.text, \"html.parser\")\n",
    "\n",
    "            # --- SELECTOR DIKEMBALIKAN SESUAI PERMINTAAN ---\n",
    "            list_artikel = soup_kategori.select(\"h3.entry-title a\")\n",
    "            \n",
    "            if not list_artikel:\n",
    "                print(\"Tidak ada tautan artikel ditemukan di halaman ini.\")\n",
    "                continue\n",
    "\n",
    "            for artikel in list_artikel:\n",
    "                # Anda bisa mengubah angka 2 ini jika ingin scrape lebih banyak per kategori\n",
    "                if artikel_diambil >= 2:\n",
    "                    break\n",
    "                \n",
    "                link_parsial = artikel.get(\"href\")\n",
    "                if not link_parsial:\n",
    "                    continue\n",
    "                \n",
    "                link = urljoin(url_home, link_parsial)\n",
    "                \n",
    "                if link in scraped_links:\n",
    "                    continue\n",
    "\n",
    "                scraped_links.add(link)\n",
    "\n",
    "                try:\n",
    "                    resp_detail = requests.get(link, timeout=10)\n",
    "                    resp_detail.raise_for_status()\n",
    "                    soup_detail = BeautifulSoup(resp_detail.text, \"html.parser\")\n",
    "\n",
    "                    # --- SELECTOR DIKEMBALIKAN SESUAI PERMINTAAN ---\n",
    "                    judul_element = soup_detail.select_one(\"h1.entry-title\")\n",
    "                    konten_berita = soup_detail.select_one(\"div.post\")\n",
    "                    \n",
    "                    if judul_element and konten_berita:\n",
    "                        judul = judul_element.get_text(strip=True)\n",
    "                        \n",
    "                        id_berita = None\n",
    "                        try:\n",
    "                            path_parts = urlparse(link).path.strip(\"/\").split(\"/\")\n",
    "                            if len(path_parts) > 1 and path_parts[1].isdigit():\n",
    "                                id_berita = path_parts[1]\n",
    "                        except (IndexError, AttributeError):\n",
    "                            id_berita = None\n",
    "                        \n",
    "                        for unwanted in konten_berita.select(\"div.baca-juga\"):\n",
    "                            unwanted.decompose()\n",
    "                        \n",
    "                        paragraf = [p.get_text(strip=True) for p in konten_berita.select(\"p\")]\n",
    "                        isi = \" \".join(paragraf)\n",
    "\n",
    "                        if isi:\n",
    "                            data_berita.append({\n",
    "                                \"id_berita\": id_berita,\n",
    "                                \"kategori\": nama_kategori,\n",
    "                                \"judul\": judul,\n",
    "                                \"isi_berita\": isi,\n",
    "                                \"link\": link\n",
    "                            })\n",
    "                            artikel_diambil += 1\n",
    "                            print(f\"({artikel_diambil}/2) Berhasil scrape: {judul[:60]}...\")\n",
    "                    \n",
    "                    time.sleep(1)\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"  -> Gagal mengambil detail dari {link}: {e}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Gagal memproses halaman kategori {url_kategori}: {e}\")\n",
    "            \n",
    "    if not data_berita:\n",
    "        print(\"\\nTidak ada berita yang berhasil di-scrape.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(data_berita)\n",
    "    df = df[[\"id_berita\", \"kategori\", \"judul\", \"isi_berita\", \"link\"]]\n",
    "    \n",
    "    df.to_csv(\"hasil_scraping_berita_bangsaonline.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\n✅ Proses scraping selesai. {len(df)} berita disimpan ke 'hasil_scraping_berita_bangsaonline.csv'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- Untuk Menjalankan Seluruh Proses Scraping ---\n",
    "if __name__ == \"__main__\":\n",
    "    df_hasil = scrape_semua_berita()\n",
    "    if df_hasil is not None:\n",
    "        pd.set_option('display.max_colwidth', 100)\n",
    "        print(\"\\nContoh hasil data:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140c532b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_berita</th>\n",
       "      <th>kategori</th>\n",
       "      <th>judul</th>\n",
       "      <th>isi_berita</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152149</td>\n",
       "      <td>Jatim</td>\n",
       "      <td>Judi Sabung Ayam di Pamekasan Digerebek, 6 Orang Diamankan</td>\n",
       "      <td>PAMEKASAN, BANGSAONLINE.com- Satreskrim Polres Pamekasan menggerebek arena judi sabung ayam di D...</td>\n",
       "      <td>https://bangsaonline.com/berita/152149/judi-sabung-ayam-di-pamekasan-digerebek-6-orang-diamankan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152148</td>\n",
       "      <td>Jatim</td>\n",
       "      <td>Pemilik Ladang Ganja di Blitar Akui Jual Ganja Kering Rp5 Juta Perkilogram</td>\n",
       "      <td>BLITAR, BANGSAONLINE.com- Pemilik ladang ganja, SA (38), warga Desa Krisik, Kecamatan Gandusari,...</td>\n",
       "      <td>https://bangsaonline.com/berita/152148/pemilik-ladang-ganja-di-blitar-akui-jual-ganja-kering-rp5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152132</td>\n",
       "      <td>Jatim Metro</td>\n",
       "      <td>Permudah Warga Urus Surat Secara Digital, Pemdes Banjarsari Luncurkan Aplikasi PAOD</td>\n",
       "      <td>SIDOARJO, BANGSAONLINE.com- Pemerintah Desa (Pemdes) Banjarsari, Kecamatan Buduran, melakukan te...</td>\n",
       "      <td>https://bangsaonline.com/berita/152132/permudah-warga-urus-surat-secara-digital-pemdes-banjarsar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152118</td>\n",
       "      <td>Jatim Metro</td>\n",
       "      <td>Fesyar 2025 Siap Digelar di Surabaya, Gubernur Khofifah Optimistis Jatim Jadi Pusat Ekonomi Syariah</td>\n",
       "      <td>SURABAYA, BANGSAONLINE.com- Gubernur Khofifah menyatakan optimisme tinggi terhadap penyelenggara...</td>\n",
       "      <td>https://bangsaonline.com/berita/152118/fesyar-2025-siap-digelar-di-surabaya-gubernur-khofifah-op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152142</td>\n",
       "      <td>Jatim Tengah</td>\n",
       "      <td>Wali Kota Kediri dan Staf Ahli Bidang Ekonomi Maritim Kemenko Pangan Tinjau Koperasi Merah Putih</td>\n",
       "      <td>KOTA KEDIRI, BANGSAONLINE.com- Wali Kota Kediri, Vinanda Prameswati, bersama Staf Ahli Bidang Ek...</td>\n",
       "      <td>https://bangsaonline.com/berita/152142/wali-kota-kediri-dan-staf-ahli-bidang-ekonomi-maritim-kem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_berita      kategori  \\\n",
       "0    152149         Jatim   \n",
       "1    152148         Jatim   \n",
       "2    152132   Jatim Metro   \n",
       "3    152118   Jatim Metro   \n",
       "4    152142  Jatim Tengah   \n",
       "\n",
       "                                                                                                 judul  \\\n",
       "0                                           Judi Sabung Ayam di Pamekasan Digerebek, 6 Orang Diamankan   \n",
       "1                           Pemilik Ladang Ganja di Blitar Akui Jual Ganja Kering Rp5 Juta Perkilogram   \n",
       "2                  Permudah Warga Urus Surat Secara Digital, Pemdes Banjarsari Luncurkan Aplikasi PAOD   \n",
       "3  Fesyar 2025 Siap Digelar di Surabaya, Gubernur Khofifah Optimistis Jatim Jadi Pusat Ekonomi Syariah   \n",
       "4     Wali Kota Kediri dan Staf Ahli Bidang Ekonomi Maritim Kemenko Pangan Tinjau Koperasi Merah Putih   \n",
       "\n",
       "                                                                                            isi_berita  \\\n",
       "0  PAMEKASAN, BANGSAONLINE.com- Satreskrim Polres Pamekasan menggerebek arena judi sabung ayam di D...   \n",
       "1  BLITAR, BANGSAONLINE.com- Pemilik ladang ganja, SA (38), warga Desa Krisik, Kecamatan Gandusari,...   \n",
       "2  SIDOARJO, BANGSAONLINE.com- Pemerintah Desa (Pemdes) Banjarsari, Kecamatan Buduran, melakukan te...   \n",
       "3  SURABAYA, BANGSAONLINE.com- Gubernur Khofifah menyatakan optimisme tinggi terhadap penyelenggara...   \n",
       "4  KOTA KEDIRI, BANGSAONLINE.com- Wali Kota Kediri, Vinanda Prameswati, bersama Staf Ahli Bidang Ek...   \n",
       "\n",
       "                                                                                                  link  \n",
       "0     https://bangsaonline.com/berita/152149/judi-sabung-ayam-di-pamekasan-digerebek-6-orang-diamankan  \n",
       "1  https://bangsaonline.com/berita/152148/pemilik-ladang-ganja-di-blitar-akui-jual-ganja-kering-rp5...  \n",
       "2  https://bangsaonline.com/berita/152132/permudah-warga-urus-surat-secara-digital-pemdes-banjarsar...  \n",
       "3  https://bangsaonline.com/berita/152118/fesyar-2025-siap-digelar-di-surabaya-gubernur-khofifah-op...  \n",
       "4  https://bangsaonline.com/berita/152142/wali-kota-kediri-dan-staf-ahli-bidang-ekonomi-maritim-kem...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hasil.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}