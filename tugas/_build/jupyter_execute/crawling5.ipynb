{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90edc683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terjadi kesalahan saat mengakses https://its.ac.id: HTTPSConnectionPool(host='its.ac.id', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002529AD947F0>, 'Connection to its.ac.id timed out. (connect timeout=None)'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def crawl_website(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Ambil semua judul h1, h2, h3\n",
    "        headings = soup.find_all(['h1', 'h2', 'h3'])\n",
    "        for heading in headings:\n",
    "            print(f\"{heading.name}: {heading.get_text()}\")\n",
    "\n",
    "        # Ambil semua link\n",
    "        links = soup.find_all('a', href=True)\n",
    "        for link in links:\n",
    "            print(f\"URL: {link['href']} | Teks: {link.get_text()}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Terjadi kesalahan saat mengakses {url}: {e}\")\n",
    "\n",
    "# Gunakan fungsi\n",
    "crawl_website(\"https://its.ac.id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8273e992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halaman Sumber | Link Keluar\n",
      "--------------------------------------------------------------------------------\n",
      "https://its.ac.id | https://www.its.ac.id/\n",
      "https://its.ac.id | https://www.its.ac.id/admission/\n",
      "https://its.ac.id | https://www.its.ac.id/current-student/\n",
      "https://its.ac.id | https://www.its.ac.id/fresher/\n",
      "https://its.ac.id | https://www.its.ac.id/lecturer-and-staff/\n",
      "https://its.ac.id | https://www.its.ac.id/parents/\n",
      "https://its.ac.id | https://www.its.ac.id/alumni/\n",
      "https://its.ac.id | http://danaabadi.its.ac.id/web/\n",
      "https://its.ac.id | https://www.youtube.com/user/itseurekatv/live\n",
      "https://its.ac.id | https://its.ac.id\n",
      "https://its.ac.id | https://www.its.ac.id/id/beranda/\n",
      "https://its.ac.id | javascript:;\n",
      "https://its.ac.id | https://my.its.ac.id/\n",
      "https://its.ac.id | https://its.ac.id\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/facts-and-history/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/ranking/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/executive-board/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/award-for-its/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/its-awards/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/vision-and-mission/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/organization-structure/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/offices-in-its/\n",
      "https://its.ac.id | http://danaabadi.its.ac.id/web/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/brand-guidelines/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/visit-its/\n",
      "https://its.ac.id | https://its.ac.id\n",
      "https://its.ac.id | https://www.its.ac.id/admission/sarjana/\n",
      "https://its.ac.id | https://www.its.ac.id/admission/pascasarjana/\n",
      "https://its.ac.id | https://www.its.ac.id/admission/sarjana-terapan/\n",
      "https://its.ac.id | https://www.its.ac.id/admission/profesi/\n",
      "https://its.ac.id | https://www.its.ac.id/admission/iup/\n",
      "https://its.ac.id | https://www.its.ac.id/international/experiencing-its/prospective-student/\n",
      "https://its.ac.id | https://its.ac.id\n",
      "https://its.ac.id | https://www.its.ac.id/study-at-its/#field\n",
      "https://its.ac.id | https://www.its.ac.id/campus-life/explore-its/\n",
      "https://its.ac.id | https://www.its.ac.id/campus-life/theres-always-something-interesting/\n",
      "https://its.ac.id | https://www.its.ac.id/study-at-its/study-program/\n",
      "https://its.ac.id | https://www.its.ac.id/international/\n",
      "https://its.ac.id | https://its.ac.id\n",
      "https://its.ac.id | https://www.its.ac.id/research/research-focus/\n",
      "https://its.ac.id | https://www.its.ac.id/research/our-researcher/\n",
      "https://its.ac.id | https://www.its.ac.id/research/student-research/\n",
      "https://its.ac.id | https://www.its.ac.id/research/research-facilities/\n",
      "https://its.ac.id | https://www.its.ac.id/research/research-publications/\n",
      "https://its.ac.id | https://www.its.ac.id/research/6613-2/\n",
      "https://its.ac.id | https://its.ac.id\n",
      "https://its.ac.id | https://www.its.ac.id/industry/product-innovation/\n",
      "https://its.ac.id | https://www.its.ac.id/stp/\n",
      "https://its.ac.id | https://www.its.ac.id/industry/facilities-and-services/\n",
      "https://its.ac.id | https://www.its.ac.id/industry/workforce-development/\n",
      "https://its.ac.id | https://its.ac.id\n",
      "https://its.ac.id | https://www.its.ac.id/initiatives/enhancing-diversity/\n",
      "https://its.ac.id | https://www.its.ac.id/initiatives/business-entrepreneurship/\n",
      "https://its.ac.id | https://www.its.ac.id/initiatives/smart-eco-campus/\n",
      "https://its.ac.id | https://www.its.ac.id/initiatives/collaborative-work/\n",
      "https://its.ac.id | https://www.its.ac.id/initiatives/sustainability2/\n",
      "https://its.ac.id | https://its.ac.id\n",
      "https://its.ac.id | https://www.its.ac.id/public-services/academic-and-student-affairs/\n",
      "https://its.ac.id | https://www.its.ac.id/public-services/planning-finance-and-infrastructure/\n",
      "https://its.ac.id | https://www.its.ac.id/public-services/human-resources-organization-and-information-system-technology/\n",
      "https://its.ac.id | https://www.its.ac.id/public-services/research-innovation-cooperation-and-alumni/\n",
      "https://its.ac.id | https://www.its.ac.id/public-services/secretary-of-the-institute/\n",
      "https://its.ac.id | https://www.its.ac.id/public-services/internal-audit/\n",
      "https://its.ac.id | https://www.its.ac.id/public-services/quality-control/\n",
      "https://its.ac.id | https://www.its.ac.id/public-services/information-and-complaints/\n",
      "https://its.ac.id | https://www.its.ac.id/public-services/global-partnerships/\n",
      "https://its.ac.id | https://www.its.ac.id/news/en/\n",
      "https://its.ac.id | javascript:;\n",
      "https://its.ac.id | javascript:;\n",
      "https://its.ac.id | https://www.its.ac.id/news/2025/09/06/geber-pameran-di-dubai-its-dorong-ekosistem-investasi-startup-indonesia/\n",
      "https://its.ac.id | https://www.its.ac.id/news/2025/09/01/bravo-spektronics-its-sabet-dua-juara-kompetisi-nasional/\n",
      "https://its.ac.id | https://www.its.ac.id/news/2025/09/03/robogo-robot-pendeteksi-sumbatan-gorong-gorong-karya-mahasiswa-its/\n",
      "https://its.ac.id | https://www.its.ac.id/admission/#beasiswa\n",
      "https://its.ac.id | https://www.its.ac.id/ppid/\n",
      "https://its.ac.id | https://www.its.ac.id/admission\n",
      "https://its.ac.id | https://www.its.ac.id/admission/#jalurseleksi\n",
      "https://its.ac.id | https://www.its.ac.id/admission/snbp/#biaya-pendidikan\n",
      "https://its.ac.id | http://www.its.ac.id/study-at-its/\n",
      "https://its.ac.id | https://its.ac.id\n",
      "https://its.ac.id | javascript:;\n",
      "https://its.ac.id | javascript:;\n",
      "https://its.ac.id | http://line.me/R/msg/text/?https://www.its.ac.id/news/en/its-doctors-study-landfill-mining-potential-in-integrated-waste-processing-sites/ - ITS Doctors Study Landfill Mining Potential in Integrated Waste Processing Sites\n",
      "https://its.ac.id | javascript:;\n",
      "https://its.ac.id | javascript:;\n",
      "https://its.ac.id | https://www.its.ac.id/news/en/its-doctors-study-landfill-mining-potential-in-integrated-waste-processing-sites/\n",
      "https://its.ac.id | https://www.its.ac.id/news/en/its-doctors-study-landfill-mining-potential-in-integrated-waste-processing-sites/\n",
      "https://its.ac.id | https://youtu.be/pEXGMDW7OEI\n",
      "https://its.ac.id | https://youtu.be/pEXGMDW7OEI\n",
      "https://its.ac.id | https://www.its.ac.id/news/en/its-indonesian-navy-supports-underwater-technology-innovation-towards-golden-indonesia-2045/\n",
      "https://its.ac.id | https://www.its.ac.id/news/en/its-indonesian-navy-supports-underwater-technology-innovation-towards-golden-indonesia-2045/\n",
      "https://its.ac.id | https://www.its.ac.id/news/en/monitoring-sea-level-rise-its-professor-develops-altimetry-satellite/\n",
      "https://its.ac.id | https://www.its.ac.id/news/en/monitoring-sea-level-rise-its-professor-develops-altimetry-satellite/\n",
      "https://its.ac.id | https://www.its.ac.id/news\n",
      "https://its.ac.id | https://www.its.ac.id/id/tentang-its/kantor-its/its-multikampus/its-sukolilo/\n",
      "https://its.ac.id | https://www.its.ac.id/id/tentang-its/kantor-its/its-multikampus/its-manyar/\n",
      "https://its.ac.id | https://www.its.ac.id/id/tentang-its/kantor-its/its-multikampus/its-cokroaminoto/\n",
      "https://its.ac.id | https://its.ac.id\n",
      "https://its.ac.id | https://www.its.ac.id/ppid/\n",
      "https://its.ac.id | https://www.its.ac.id/ppid/whistle-blowing-system/\n",
      "https://its.ac.id | https://www.lapor.go.id\n",
      "https://its.ac.id | https://www.its.ac.id/ppid/laporan-keuangan/\n",
      "https://its.ac.id | https://www.kemdikbud.go.id\n",
      "https://its.ac.id | https://www.its.ac.id/gpr/\n",
      "https://its.ac.id | https://www.its.ac.id/burb/id/layanan-plt/\n",
      "https://its.ac.id | https://servicedesk.its.ac.id/\n",
      "https://its.ac.id | https://www.its.ac.id/id/layanan/\n",
      "https://its.ac.id | https://www.its.ac.id/agenda/cenim-2025-the-6th-international-conference-on-computer-engineering-network-and-intelligent-multimedia/\n",
      "https://its.ac.id | https://www.its.ac.id/agenda/departement-of-physics-the-4th-international-symposium-on-physics-and-applications-ispa-2025/\n",
      "https://its.ac.id | https://www.its.ac.id/creabiz-international-week/\n",
      "https://its.ac.id | https://www.its.ac.id/agenda/\n",
      "https://its.ac.id | https://www.youtube.com/user/itseurekatv\n",
      "https://its.ac.id | https://www.instagram.com/its_campus/\n",
      "https://its.ac.id | https://id-id.facebook.com/InstitutTeknologiSepuluhNopember/\n",
      "https://its.ac.id | https://twitter.com/its_campus\n",
      "https://its.ac.id | https://id.linkedin.com/school/its-campus/\n",
      "https://its.ac.id | https://lin.ee/fxmXOiU\n",
      "https://its.ac.id | https://www.tiktok.com/@its_campus\n",
      "https://its.ac.id | https://scholar.its.ac.id/\n",
      "https://its.ac.id | https://www.its.ac.id/campus-life/\n",
      "https://its.ac.id | https://www.its.ac.id/research/\n",
      "https://its.ac.id | https://www.its.ac.id/industry/\n",
      "https://its.ac.id | https://www.its.ac.id/initiatives/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/\n",
      "https://its.ac.id | https://www.its.ac.id/en/study-at-its/#field\n",
      "https://its.ac.id | https://www.its.ac.id/study-at-its/faculties-and-departments/\n",
      "https://its.ac.id | https://www.its.ac.id/en/study-at-its/#studyprogram\n",
      "https://its.ac.id | https://www.its.ac.id/en/study-at-its/#international-students\n",
      "https://its.ac.id | https://www.its.ac.id/campus-life/explore-its/\n",
      "https://its.ac.id | https://www.its.ac.id/campus-life/student-activities/\n",
      "https://its.ac.id | https://www.its.ac.id/id/explore-surabaya/\n",
      "https://its.ac.id | https://www.its.ac.id/research/research-focus/\n",
      "https://its.ac.id | https://www.its.ac.id/research/student-research/\n",
      "https://its.ac.id | https://www.its.ac.id/research/research-publications/\n",
      "https://its.ac.id | https://www.its.ac.id/research/our-researcher/\n",
      "https://its.ac.id | https://www.its.ac.id/research/research-facilities/\n",
      "https://its.ac.id | https://www.its.ac.id/research/research-collaborations/\n",
      "https://its.ac.id | https://www.its.ac.id/industry/science-techno-park/\n",
      "https://its.ac.id | https://www.its.ac.id/industry/product-innovation/\n",
      "https://its.ac.id | https://www.its.ac.id/industry/workforce-development/\n",
      "https://its.ac.id | https://www.its.ac.id/industry/facilities-and-services/\n",
      "https://its.ac.id | https://www.its.ac.id/initiatives/enhancing-diversity/\n",
      "https://its.ac.id | https://www.its.ac.id/initiatives/smart-eco-campus/\n",
      "https://its.ac.id | https://www.its.ac.id/initiatives/business-entrepreneurship/\n",
      "https://its.ac.id | https://www.its.ac.id/initiatives/collaborative-work/\n",
      "https://its.ac.id | https://www.its.ac.id/initiatives/sustainability2/\n",
      "https://its.ac.id | https://www.its.ac.id/id/brief-profile/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/offices-in-its/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/visit-its/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/its-awards/\n",
      "https://its.ac.id | https://www.its.ac.id/?page_id=11494\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/executive-board/\n",
      "https://its.ac.id | https://www.its.ac.id/about-its/vision-and-mission/\n",
      "https://its.ac.id | https://its.ac.id\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def crawl_website(url):\n",
    "    \"\"\"\n",
    "    Fungsi untuk crawling sebuah website, mengambil semua link, \n",
    "    dan menampilkannya dalam format: [Halaman Sumber] | [Link Keluar Absolut]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Melempar error jika status code bukan 200 OK\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        print(f\"Halaman Sumber | Link Keluar\")\n",
    "        print(\"-\" * 80) # Membuat garis pemisah agar rapi\n",
    "\n",
    "        # Ambil semua tag <a> yang memiliki atribut href\n",
    "        links = soup.find_all('a', href=True)\n",
    "        \n",
    "        for link in links:\n",
    "            # Mengambil nilai href dari link\n",
    "            href = link['href']\n",
    "            \n",
    "            # Mengubah link relatif (misal: /admission) menjadi link absolut\n",
    "            # urljoin akan menggabungkan URL dasar dengan href\n",
    "            absolute_url = urljoin(url, href)\n",
    "            \n",
    "            # Mencetak dengan format yang diminta\n",
    "            print(f\"{url} | {absolute_url}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Terjadi kesalahan saat mengakses {url}: {e}\")\n",
    "\n",
    "# --- Gunakan fungsi ---\n",
    "crawl_website(\"https://its.ac.id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd9b6893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menemukan 154 link. Menyimpan ke hasil_scraping_its.csv...\n",
      "✅ Selesai! Data berhasil disimpan ke file 'hasil_scraping_its.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import csv\n",
    "\n",
    "def crawl_and_save_to_csv(url, filename=\"output.csv\"):\n",
    "    \"\"\"\n",
    "    Fungsi untuk crawling website, mengambil semua link, \n",
    "    dan menyimpannya ke dalam file CSV.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Melempar error jika status code bukan 200 OK\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Membuka file CSV untuk ditulis ('w' = write)\n",
    "        # newline='' untuk menghindari baris kosong antar baris di file CSV\n",
    "        # encoding='utf-8' untuk mendukung karakter internasional\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "            # Membuat object writer dari modul csv\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Menulis baris header (judul kolom)\n",
    "            writer.writerow([\"Halaman Sumber\", \"Link Keluar\"])\n",
    "            \n",
    "            # Ambil semua tag <a> yang memiliki atribut href\n",
    "            links = soup.find_all('a', href=True)\n",
    "            \n",
    "            print(f\"Menemukan {len(links)} link. Menyimpan ke {filename}...\")\n",
    "\n",
    "            for link in links:\n",
    "                href = link['href']\n",
    "                absolute_url = urljoin(url, href)\n",
    "                \n",
    "                # Menulis satu baris data ke file CSV\n",
    "                # Isinya adalah https://www.seoptimer.com/id/blog/url-absolut-vs-url-relatif/\n",
    "                writer.writerow([url, absolute_url])\n",
    "\n",
    "        print(f\"✅ Selesai! Data berhasil disimpan ke file '{filename}'\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Terjadi kesalahan saat mengakses {url}: {e}\")\n",
    "\n",
    "# --- Gunakan fungsi ---\n",
    "# Kita tentukan URL target dan nama file output yang diinginkan\n",
    "target_url = \"https://its.ac.id\"\n",
    "output_filename = \"hasil_scraping_its.csv\"\n",
    "crawl_and_save_to_csv(target_url, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b76576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memeriksa 154 total link yang ditemukan di https://its.ac.id...\n",
      "\n",
      "--- Hasil Scraping (Filter Link Internal) ---\n",
      "        Halaman Sumber                             Link Keluar (Internal)\n",
      "0    https://its.ac.id                             https://www.its.ac.id/\n",
      "1    https://its.ac.id                   https://www.its.ac.id/admission/\n",
      "2    https://its.ac.id             https://www.its.ac.id/current-student/\n",
      "3    https://its.ac.id                     https://www.its.ac.id/fresher/\n",
      "4    https://its.ac.id          https://www.its.ac.id/lecturer-and-staff/\n",
      "..                 ...                                                ...\n",
      "119  https://its.ac.id         https://www.its.ac.id/about-its/visit-its/\n",
      "120  https://its.ac.id        https://www.its.ac.id/about-its/its-awards/\n",
      "121  https://its.ac.id               https://www.its.ac.id/?page_id=11494\n",
      "122  https://its.ac.id   https://www.its.ac.id/about-its/executive-board/\n",
      "123  https://its.ac.id  https://www.its.ac.id/about-its/vision-and-mis...\n",
      "\n",
      "[124 rows x 2 columns]\n",
      "\n",
      "✅ Sukses! Data telah disimpan ke file 'link_internal_its.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import pandas as pd\n",
    "\n",
    "def crawl_filter_display_and_save(url, filename=\"hasil_scraping.csv\"):\n",
    "    \"\"\"\n",
    "    Fungsi lengkap untuk:\n",
    "    1. Crawling website.\n",
    "    2. Mengambil HANYA link internal (domain yang sama).\n",
    "    3. Menampilkannya dalam format Pandas DataFrame.\n",
    "    4. Menyimpannya ke dalam file CSV.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Dapatkan nama domain dasar dari URL input untuk perbandingan\n",
    "        base_hostname = urlparse(url).hostname.replace('www.', '')\n",
    "\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        scraped_data = []\n",
    "        links = soup.find_all('a', href=True)\n",
    "        \n",
    "        print(f\"Memeriksa {len(links)} total link yang ditemukan di {url}...\")\n",
    "\n",
    "        for link in links:\n",
    "            href = link['href']\n",
    "            # Abaikan link anchor (#) dan link javascript yang tidak relevan\n",
    "            if href.startswith('#') or href.startswith('javascript:'):\n",
    "                continue\n",
    "                \n",
    "            absolute_url = urljoin(url, href)\n",
    "            \n",
    "            # Lakukan Pengecekan Domain\n",
    "            try:\n",
    "                link_hostname = urlparse(absolute_url).hostname\n",
    "                if link_hostname and link_hostname.endswith(base_hostname):\n",
    "                    scraped_data.append([url, absolute_url])\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        # --- Bagian DataFrame ---\n",
    "        # Buat DataFrame dari data yang sudah difilter\n",
    "        df = pd.DataFrame(scraped_data, columns=[\"Halaman Sumber\", \"Link Keluar (Internal)\"])\n",
    "        \n",
    "        print(\"\\n--- Hasil Scraping (Filter Link Internal) ---\")\n",
    "        if df.empty:\n",
    "            print(\"Tidak ada link internal yang ditemukan.\")\n",
    "            return # Hentikan fungsi jika tidak ada data untuk disimpan\n",
    "\n",
    "        # Tampilkan DataFrame\n",
    "        print(df)\n",
    "\n",
    "        # --- Bagian Penyimpanan CSV ---\n",
    "        try:\n",
    "            df.to_csv(filename, index=False, encoding='utf-8')\n",
    "            print(f\"\\n✅ Sukses! Data telah disimpan ke file '{filename}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Gagal menyimpan file CSV: {e}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Terjadi kesalahan saat mengakses {url}: {e}\")\n",
    "\n",
    "# --- Gunakan fungsi ---\n",
    "target_url = \"https://its.ac.id\"\n",
    "output_filename = \"link_internal_its.csv\"\n",
    "crawl_filter_display_and_save(target_url, output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}