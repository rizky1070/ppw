{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89da0803",
   "metadata": {},
   "source": [
    "# CBOW Berita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03765425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from gensim) (7.3.1)\n",
      "Requirement already satisfied: wrapt in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4319e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e3d471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 1: MEMPERSIAPKAN CORPUS ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses persiapan corpus selesai.\n",
      "Berikut adalah contoh 1 dokumen (berita) yang sudah diubah menjadi daftar token:\n",
      "['sidoarjobangsaonlinecom', 'proses', 'cari', 'korban', 'santri', 'timbun', 'runtuh', 'musala', 'ambruk', 'pondok', 'pesantren', 'ponpes', 'alkhoziny', 'budur', 'sidoarjo', 'rabu', 'siang', 'santri', 'enggan', 'nama', 'aku', 'santri', 'cor', 'bangun', 'hukum', 'santri', 'ikut', 'giat', 'ambruk', 'pas', 'salat', 'jemaah', 'imam', 'selamat', 'temanteman', 'timpa', 'santri', 'rabu', 'tim', 'sar', 'gabung', 'jibaku', 'sisir', 'puingpuing', 'bangun', 'lantai', 'total', 'ratus', 'santri', 'hasil', 'evakuasi', 'cari', 'musibah', 'milu', 'selip', 'kisah', 'hari', 'santri', 'pondok', 'salah', 'satu', 'biasa', 'beri', 'hukum', 'ikut', 'giat', 'pesantren', 'hukum', 'bantu', 'cor', 'bangun', 'santri', 'tahu', 'bolos', 'hukum', 'bantu', 'ngecor', 'tukang', 'santri', 'wajib', 'suruh', 'bantu', 'kena', 'hukum', 'santri', 'enam', 'mondok', 'untung', 'musala', 'ambruk', 'lokasi', 'pondok', 'pondok', 'musala', 'ambruk', 'ratus', 'santri', 'salat', 'asar', 'timpa', 'runtuh', 'cerita', 'ungkap', 'abdul', 'keluarga', 'salah', 'korban', 'keponakan', 'asal', 'madura', 'santri', 'bantu', 'cor', 'musala', 'runtuh', 'ngecor', 'jatuh', 'luka', 'wajah', 'gigi', 'copot', 'pungkas', 'cat']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast # Library untuk mengubah string menjadi list\n",
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "\n",
    "# --- 1. Persiapan Corpus ---\n",
    "print(\"--- TAHAP 1: MEMPERSIAPKAN CORPUS ---\")\n",
    "# Load kembali data Anda (atau lanjutkan dari DataFrame yang sudah ada)\n",
    "df = pd.read_csv('hasil_preprocessing_berita.csv')\n",
    "\n",
    "# --- Konversi kolom 'hasil_preprocessing' dari string ke list ---\n",
    "# Ini adalah langkah penting!\n",
    "# ast.literal_eval akan membaca string \"['a', 'b']\" dan mengubahnya menjadi list ['a', 'b']\n",
    "df['tokens'] = df['hasil_preprocessing'].apply(ast.literal_eval)\n",
    "\n",
    "# Buat corpus yang siap untuk dilatih\n",
    "corpus = df['tokens'].tolist()\n",
    "\n",
    "\n",
    "print(\"Proses persiapan corpus selesai.\")\n",
    "print(\"Berikut adalah contoh 1 dokumen (berita) yang sudah diubah menjadi daftar token:\")\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10107212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,725 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,725 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,757 : INFO : collected 18096 word types from a corpus of 207077 raw words and 925 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,759 : INFO : Creating a fresh vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,795 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 10268 unique words (56.74% of original 18096, drops 7828)', 'datetime': '2025-10-02T10:34:14.795250', 'gensim': '4.3.3', 'python': '3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,796 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 199249 word corpus (96.22% of original 207077, drops 7828)', 'datetime': '2025-10-02T10:34:14.796250', 'gensim': '4.3.3', 'python': '3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,846 : INFO : deleting the raw counts dictionary of 18096 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,847 : INFO : sample=0.001 downsamples 16 most-common words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,848 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 196640.93131086108 word corpus (98.7%% of prior 199249)', 'datetime': '2025-10-02T10:34:14.848758', 'gensim': '4.3.3', 'python': '3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 2: MELATIH MODEL WORD2VEC (CBOW) ---\n",
      "Parameter: Dimensi vektor = 150, Arsitektur = CBOW\n",
      "Gensim akan menampilkan log proses training di bawah ini:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,931 : INFO : estimated required memory for 10268 words and 150 dimensions: 17455600 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,932 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,942 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-10-02T10:34:14.942546', 'gensim': '4.3.3', 'python': '3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:14,943 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 10268 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-10-02T10:34:14.943542', 'gensim': '4.3.3', 'python': '3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:15,139 : INFO : EPOCH 0: training on 207077 raw words (196648 effective words) took 0.2s, 1019865 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:15,299 : INFO : EPOCH 1: training on 207077 raw words (196662 effective words) took 0.2s, 1268102 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:15,454 : INFO : EPOCH 2: training on 207077 raw words (196608 effective words) took 0.2s, 1297739 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:15,616 : INFO : EPOCH 3: training on 207077 raw words (196688 effective words) took 0.2s, 1242379 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:15,774 : INFO : EPOCH 4: training on 207077 raw words (196725 effective words) took 0.2s, 1283448 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:15,774 : INFO : Word2Vec lifecycle event {'msg': 'training on 1035385 raw words (983331 effective words) took 0.8s, 1184470 effective words/s', 'datetime': '2025-10-02T10:34:15.774951', 'gensim': '4.3.3', 'python': '3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:34:15,775 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=10268, vector_size=150, alpha=0.025>', 'datetime': '2025-10-02T10:34:15.775961', 'gensim': '4.3.3', 'python': '3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pelatihan model selesai!\n",
      "\n",
      "--- Melihat Hasil Pelatihan Model ---\n",
      "Model berhasil mempelajari 10268 kata unik.\n",
      "\n",
      "Contoh kata yang paling mirip dengan 'polisi':\n",
      "[('tindak', 0.9989293217658997), ('lari', 0.9984794855117798), ('keluh', 0.9983461499214172), ('polsek', 0.9983104467391968), ('tahap', 0.9979819059371948)]\n",
      "\n",
      "Contoh kata yang paling mirip dengan 'surabaya':\n",
      "[('mojokerto', 0.9912481307983398), ('pacet', 0.9809286594390869), ('pn', 0.9808470010757446), ('jombang', 0.9805688858032227), ('wakil', 0.9728435277938843)]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Melatih Model Word2Vec (dengan Proses Terlihat) ---\n",
    "\n",
    "print(\"--- TAHAP 2: MELATIH MODEL WORD2VEC (CBOW) ---\")\n",
    "\n",
    "# Mengaktifkan logging untuk melihat proses training dari Gensim\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "embedding_dim = 150\n",
    "print(f\"Parameter: Dimensi vektor = {embedding_dim}, Arsitektur = CBOW\")\n",
    "print(\"Gensim akan menampilkan log proses training di bawah ini:\")\n",
    "\n",
    "model_cbow = Word2Vec(\n",
    "    sentences=corpus,\n",
    "    vector_size=embedding_dim,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    sg=0,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "print(\"\\nPelatihan model selesai!\")\n",
    "print(\"\\n--- Melihat Hasil Pelatihan Model ---\")\n",
    "# Mengetahui ukuran kosakata yang berhasil dipelajari model\n",
    "vocab_size = len(model_cbow.wv.index_to_key)\n",
    "print(f\"Model berhasil mempelajari {vocab_size} kata unik.\")\n",
    "\n",
    "# Melihat kata-kata yang paling mirip secara semantik dengan kata tertentu\n",
    "# Ini membuktikan model sudah belajar konteks\n",
    "try:\n",
    "    print(\"\\nContoh kata yang paling mirip dengan 'polisi':\")\n",
    "    print(model_cbow.wv.most_similar('polisi', topn=5))\n",
    "\n",
    "    print(\"\\nContoh kata yang paling mirip dengan 'surabaya':\")\n",
    "    print(model_cbow.wv.most_similar('surabaya', topn=5))\n",
    "except KeyError as e:\n",
    "    print(f\"\\nKata {e} tidak ditemukan di vocabulary (mungkin karena jarang muncul).\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883b7da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 3: MEMBEDAH PROSES AGREGRASI MENJADI VEKTOR DOKUMEN ---\n",
      "Kita akan menganalisis berita pertama:\n",
      "Isi berita (token): ['sidoarjobangsaonlinecom', 'proses', 'cari', 'korban', 'santri', 'timbun', 'runtuh', 'musala', 'ambruk', 'pondok', 'pesantren', 'ponpes', 'alkhoziny', 'budur', 'sidoarjo', 'rabu', 'siang', 'santri', 'enggan', 'nama', 'aku', 'santri', 'cor', 'bangun', 'hukum', 'santri', 'ikut', 'giat', 'ambruk', 'pas', 'salat', 'jemaah', 'imam', 'selamat', 'temanteman', 'timpa', 'santri', 'rabu', 'tim', 'sar', 'gabung', 'jibaku', 'sisir', 'puingpuing', 'bangun', 'lantai', 'total', 'ratus', 'santri', 'hasil', 'evakuasi', 'cari', 'musibah', 'milu', 'selip', 'kisah', 'hari', 'santri', 'pondok', 'salah', 'satu', 'biasa', 'beri', 'hukum', 'ikut', 'giat', 'pesantren', 'hukum', 'bantu', 'cor', 'bangun', 'santri', 'tahu', 'bolos', 'hukum', 'bantu', 'ngecor', 'tukang', 'santri', 'wajib', 'suruh', 'bantu', 'kena', 'hukum', 'santri', 'enam', 'mondok', 'untung', 'musala', 'ambruk', 'lokasi', 'pondok', 'pondok', 'musala', 'ambruk', 'ratus', 'santri', 'salat', 'asar', 'timpa', 'runtuh', 'cerita', 'ungkap', 'abdul', 'keluarga', 'salah', 'korban', 'keponakan', 'asal', 'madura', 'santri', 'bantu', 'cor', 'musala', 'runtuh', 'ngecor', 'jatuh', 'luka', 'wajah', 'gigi', 'copot', 'pungkas', 'cat']\n",
      "\n",
      "Vektor untuk 3 kata pertama dalam berita:\n",
      "  - Vektor kata 'sidoarjobangsaonlinecom': [ 0.01630391 -0.03513356 -0.03584009 -0.02173803 -0.00085699]... (ditampilkan 5 dimensi pertama)\n",
      "  - Vektor kata 'proses': [ 0.6113657  -0.4057105  -0.6268387  -0.10718356  0.02659323]... (ditampilkan 5 dimensi pertama)\n",
      "  - Vektor kata 'cari': [ 0.39067325 -0.30204904 -0.49456948 -0.11411975 -0.02882157]... (ditampilkan 5 dimensi pertama)\n",
      "\n",
      "Hasil vektor dokumen (setelah dirata-ratakan):\n",
      "[ 0.06921634 -0.08688264 -0.2111469  -0.27367693 -0.07913538 -0.5037593\n",
      "  0.10594793  0.27894735  0.05341049  0.33171484]... (ditampilkan 10 dimensi pertama)\n",
      "Panjang vektor: 150 dimensi (sesuai yang kita tentukan).\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Membedah Proses Agregasi Vektor Dokumen ---\n",
    "print(\"--- TAHAP 3: MEMBEDAH PROSES AGREGRASI MENJADI VEKTOR DOKUMEN ---\")\n",
    "\n",
    "def create_document_vector(doc, model, num_features):\n",
    "    word_vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(num_features)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "contoh_berita = corpus[0]\n",
    "print(\"Kita akan menganalisis berita pertama:\")\n",
    "print(f\"Isi berita (token): {contoh_berita}\")\n",
    "\n",
    "print(\"\\nVektor untuk 3 kata pertama dalam berita:\")\n",
    "for i, word in enumerate(contoh_berita[:3]):\n",
    "    if word in model_cbow.wv:\n",
    "        print(f\"  - Vektor kata '{word}': {model_cbow.wv[word][:5]}... (ditampilkan 5 dimensi pertama)\")\n",
    "    else:\n",
    "        print(f\"  - Kata '{word}' tidak ada di vocabulary model.\")\n",
    "\n",
    "vektor_berita_contoh = create_document_vector(contoh_berita, model_cbow, embedding_dim)\n",
    "print(\"\\nHasil vektor dokumen (setelah dirata-ratakan):\")\n",
    "print(f\"{vektor_berita_contoh[:10]}... (ditampilkan 10 dimensi pertama)\")\n",
    "print(f\"Panjang vektor: {len(vektor_berita_contoh)} dimensi (sesuai yang kita tentukan).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0599b6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 4: MEMBUAT DATAFRAME AKHIR ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses pembuatan DataFrame selesai.\n",
      "Berikut adalah contoh hasil akhirnya:\n",
      "      dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
      "0  0.069216 -0.086883 -0.211147 -0.273677 -0.079135 -0.503759  0.105948   \n",
      "1  0.238639 -0.226196 -0.284154 -0.117963  0.003578 -0.368139  0.128672   \n",
      "2  0.089199 -0.170814 -0.168784 -0.214527 -0.003419 -0.534771  0.114673   \n",
      "3  0.277909 -0.224949 -0.320442 -0.066012  0.000749 -0.262456  0.083818   \n",
      "4  0.201823 -0.180752 -0.297515 -0.148686 -0.025942 -0.332840  0.114246   \n",
      "\n",
      "      dim_8     dim_9    dim_10  ...   dim_142   dim_143   dim_144   dim_145  \\\n",
      "0  0.278947  0.053410  0.331715  ...  0.306150  0.417316  0.243297  0.462066   \n",
      "1  0.096986  0.029187  0.308865  ...  0.176685  0.320070  0.144839  0.334102   \n",
      "2  0.125485 -0.060687  0.348521  ...  0.329579  0.411935  0.290931  0.445818   \n",
      "3  0.167154  0.104912  0.233309  ...  0.081702  0.230552  0.116026  0.306610   \n",
      "4  0.163369  0.076258  0.266791  ...  0.160711  0.298401  0.152861  0.324403   \n",
      "\n",
      "    dim_146   dim_147   dim_148   dim_149   dim_150  kategori  \n",
      "0  0.092092 -0.512174 -0.183966  0.204816 -0.221595     Jatim  \n",
      "1  0.091501 -0.414204 -0.177591  0.192453 -0.199659     Jatim  \n",
      "2  0.032889 -0.560976 -0.240336  0.239579 -0.309966     Jatim  \n",
      "3  0.151423 -0.288375 -0.136695  0.169283 -0.119104     Jatim  \n",
      "4  0.107670 -0.375295 -0.168463  0.164236 -0.167032     Jatim  \n",
      "\n",
      "[5 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Membuat DataFrame Akhir ---\n",
    "print(\"--- TAHAP 4: MEMBUAT DATAFRAME AKHIR ---\")\n",
    "doc_vectors = [create_document_vector(doc, model_cbow, embedding_dim) for doc in corpus]\n",
    "cbow_df = pd.DataFrame(doc_vectors, columns=[f'dim_{i+1}' for i in range(embedding_dim)])\n",
    "cbow_df['kategori'] = df['kategori'].values\n",
    "\n",
    "print(\"Proses pembuatan DataFrame selesai.\")\n",
    "print(\"Berikut adalah contoh hasil akhirnya:\")\n",
    "print(cbow_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}