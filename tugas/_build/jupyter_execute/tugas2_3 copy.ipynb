{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085e27af",
   "metadata": {},
   "source": [
    "# Crawling Berita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb1f771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencari kategori berita di bangsaonline.com...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ditemukan 37 kategori berita valid.\n",
      "\n",
      "--- Scraping Kategori: JATIM ---\n",
      "   -> Mengambil halaman 1: https://bangsaonline.com/kanal/jawa-timur\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/25) Berhasil scrape: Kampung Semanggi antar Surabaya Raih Juara 1 Kategori Inovas...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/25) Berhasil scrape: PKB Tuban Tasyakuran atas Anugerah Gelar Pahlawan Nasional U...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3/25) Berhasil scrape: BRI Super League Pekan 13, Persik Kediri Incar Hasil Kemenan...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4/25) Berhasil scrape: Putusan MK Soal Jabatan Polisi di Luar Polri, Dosen UWP: Pem...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5/25) Berhasil scrape: Erupsi Semeru Naik ke Level Awas, Gubernur Khofifah Imbau Wa...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6/25) Berhasil scrape: Tanggul Kali Lamong Jebol, Permukiman Warga di Selatan Gresi...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7/25) Berhasil scrape: Eksekusi Lahan 7.798 Meter Persegi di Sukodono Diwarnai Kete...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8/25) Berhasil scrape: Tanah Longsor di Ponorogo, 1 Rumah dan 7 Kendaraan Tertimbun...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9/25) Berhasil scrape: Warga Diminta Waspada! Ada 4 Potensi Bencana di Sumenep saat...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10/25) Berhasil scrape: Polres Gresik Amankan Pelaku Pencurian Motor dengan Modus Be...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11/25) Berhasil scrape: Golkar Gresik Siapkan KH Ma’rufsyah untuk Pilkada 2030...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12/25) Berhasil scrape: Ganjal Mesin ATM di Rest Area Tol Sidoarjo, 6 Pelaku Kuras U...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13/25) Berhasil scrape: Cuaca Kota Surabaya Hari ini Rabu, 19 November 2025: Diperki...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14/25) Berhasil scrape: Audiensi ke Disnaker Gresik, SOKSI Bahas 3 Problem Ketenagak...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15/25) Berhasil scrape: Mayat di Arteri Porong Ternyata Korban Pembunuhan, Tersangka...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16/25) Berhasil scrape: Ungkap Rayuan Cinta Habib Bahar Smith, Helwa Bachmid Ngaku I...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17/25) Berhasil scrape: Harga Emas Antam Hari Ini Merangkak, 1 Gram Naik Rp21 Ribu...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18/25) Berhasil scrape: Rata-Rata Harga Pangan Nasional per 19 November 2025 Naik, C...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "# Menambahkan header User-Agent adalah praktik yang baik\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "# Jumlah maksimal percobaan jika request gagal\n",
    "MAX_RETRIES = 3\n",
    "# Jumlah artikel yang diinginkan per kategori\n",
    "ARTIKEL_PER_KATEGORI = 25\n",
    "\n",
    "def dapatkan_kategori_berita():\n",
    "    \"\"\"\n",
    "    Fungsi untuk mengambil daftar semua kategori berita dari menu navigasi\n",
    "    website bangsaonline.com.\n",
    "    \"\"\"\n",
    "    print(\"Mencari kategori berita di bangsaonline.com...\")\n",
    "    kategori_list = {}\n",
    "    url_home = \"https://bangsaonline.com/\"\n",
    "    try:\n",
    "        response = requests.get(url_home, headers=HEADERS, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        nav_menu = soup.select_one('ul#nav')\n",
    "        if not nav_menu:\n",
    "            print(\"Menu navigasi (ul#nav) tidak ditemukan.\")\n",
    "            return {}\n",
    "\n",
    "        for item in nav_menu.find_all(\"a\"):\n",
    "            href = item.get(\"href\")\n",
    "            nama_kategori = item.get_text(strip=True)\n",
    "            \n",
    "            if href and nama_kategori:\n",
    "                path_parts = urlparse(href).path.strip(\"/\").split(\"/\")\n",
    "                \n",
    "                if len(path_parts) == 2 and path_parts[0] == 'kanal':\n",
    "                    url_lengkap = urljoin(url_home, href)\n",
    "                    if nama_kategori not in kategori_list:\n",
    "                        kategori_list[nama_kategori] = url_lengkap\n",
    "\n",
    "        print(f\"Ditemukan {len(kategori_list)} kategori berita valid.\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Gagal mengambil daftar kategori berita: {e}\")\n",
    "        \n",
    "    return kategori_list\n",
    "\n",
    "def scrape_semua_berita():\n",
    "    \"\"\"\n",
    "    Fungsi utama untuk melakukan scraping berita dari semua kategori yang ditemukan,\n",
    "    dengan implementasi pagination dan retry mechanism.\n",
    "    \"\"\"\n",
    "    daftar_kategori = dapatkan_kategori_berita()\n",
    "\n",
    "    if not daftar_kategori:\n",
    "        print(\"Tidak ada kategori yang bisa di-scrape. Program berhenti.\")\n",
    "        return\n",
    "\n",
    "    data_berita = []\n",
    "    scraped_links = set()\n",
    "    url_home = \"https://bangsaonline.com/\"\n",
    "\n",
    "    for nama_kategori, url_kategori in daftar_kategori.items():\n",
    "        print(f\"\\n--- Scraping Kategori: {nama_kategori.upper()} ---\")\n",
    "        artikel_diambil = 0\n",
    "        halaman_ke = 1\n",
    "        \n",
    "        # Loop akan berjalan selama artikel yang diambil < target\n",
    "        while artikel_diambil < ARTIKEL_PER_KATEGORI:\n",
    "            \n",
    "            # --- LOGIKA PAGINATION BARU ---\n",
    "            if halaman_ke == 1:\n",
    "                current_url = url_kategori\n",
    "            else:\n",
    "                current_url = f\"{url_kategori}?page={halaman_ke}\"\n",
    "            \n",
    "            print(f\"   -> Mengambil halaman {halaman_ke}: {current_url}\")\n",
    "            \n",
    "            response_kategori = None\n",
    "            for attempt in range(MAX_RETRIES):\n",
    "                try:\n",
    "                    response_kategori = requests.get(current_url, headers=HEADERS, timeout=15)\n",
    "                    response_kategori.raise_for_status()\n",
    "                    break\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"      Gagal mengambil halaman kategori (percobaan {attempt + 1}/{MAX_RETRIES}): {e}\")\n",
    "                    time.sleep(2)\n",
    "            \n",
    "            if not response_kategori:\n",
    "                print(f\"   Gagal mengambil halaman kategori {current_url} setelah {MAX_RETRIES} percobaan. Lanjut ke kategori berikutnya.\")\n",
    "                break\n",
    "\n",
    "            soup_kategori = BeautifulSoup(response_kategori.text, \"html.parser\")\n",
    "            list_artikel = soup_kategori.select(\"h3.entry-title a\")\n",
    "            \n",
    "            # --- KONDISI BERHENTI BARU ---\n",
    "            # Jika halaman tidak ada artikelnya, hentikan untuk kategori ini\n",
    "            if not list_artikel:\n",
    "                print(\"   Tidak ada artikel di halaman ini, selesai untuk kategori ini.\")\n",
    "                break\n",
    "\n",
    "            for artikel in list_artikel:\n",
    "                if artikel_diambil >= ARTIKEL_PER_KATEGORI:\n",
    "                    break\n",
    "                \n",
    "                link = urljoin(url_home, artikel.get(\"href\", \"\"))\n",
    "                if not link or link in scraped_links:\n",
    "                    continue\n",
    "\n",
    "                scraped_links.add(link)\n",
    "                \n",
    "                resp_detail = None\n",
    "                for attempt in range(MAX_RETRIES):\n",
    "                    try:\n",
    "                        resp_detail = requests.get(link, headers=HEADERS, timeout=15)\n",
    "                        resp_detail.raise_for_status()\n",
    "                        break\n",
    "                    except requests.exceptions.RequestException as e:\n",
    "                        print(f\"      Gagal mengambil detail dari {link} (percobaan {attempt + 1}/{MAX_RETRIES})\")\n",
    "                        time.sleep(1)\n",
    "\n",
    "                if not resp_detail:\n",
    "                    print(f\"   -> Gagal total mengambil detail dari {link}. Melewatkan artikel ini.\")\n",
    "                    continue\n",
    "                        \n",
    "                soup_detail = BeautifulSoup(resp_detail.text, \"html.parser\")\n",
    "                judul_element = soup_detail.select_one(\"h1.entry-title\")\n",
    "                konten_berita = soup_detail.select_one(\"div.post\")\n",
    "                \n",
    "                if judul_element and konten_berita:\n",
    "                    judul = judul_element.get_text(strip=True)\n",
    "                    \n",
    "                    id_berita = None\n",
    "                    try:\n",
    "                        path_parts = urlparse(link).path.strip(\"/\").split(\"/\")\n",
    "                        if len(path_parts) > 1 and path_parts[1].isdigit():\n",
    "                            id_berita = path_parts[1]\n",
    "                    except (IndexError, AttributeError):\n",
    "                        id_berita = None\n",
    "                    \n",
    "                    for unwanted in konten_berita.select(\"div.baca-juga, div.shared-icons\"):\n",
    "                        unwanted.decompose()\n",
    "                    \n",
    "                    paragraf = [p.get_text(strip=True) for p in konten_berita.select(\"p\")]\n",
    "                    isi = \" \".join(paragraf)\n",
    "\n",
    "                    if isi:\n",
    "                        data_berita.append({\n",
    "                            \"id_berita\": id_berita, \"kategori\": nama_kategori,\n",
    "                            \"judul\": judul, \"isi_berita\": isi, \"link\": link\n",
    "                        })\n",
    "                        artikel_diambil += 1\n",
    "                        print(f\"({artikel_diambil}/{ARTIKEL_PER_KATEGORI}) Berhasil scrape: {judul[:60]}...\")\n",
    "                \n",
    "                time.sleep(1) \n",
    "\n",
    "            # Pindah ke halaman berikutnya untuk iterasi selanjutnya\n",
    "            halaman_ke += 1\n",
    "\n",
    "    if not data_berita:\n",
    "        print(\"\\nTidak ada berita yang berhasil di-scrape.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(data_berita)\n",
    "    df = df[[\"id_berita\", \"kategori\", \"judul\", \"isi_berita\", \"link\"]]\n",
    "    \n",
    "    nama_file = \"hasil_scraping_berita_bangsaonline.csv\"\n",
    "    df.to_csv(nama_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\n✅ Proses scraping selesai. {len(df)} berita disimpan ke '{nama_file}'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- Untuk Menjalankan Seluruh Proses Scraping ---\n",
    "if __name__ == \"__main__\":\n",
    "    df_hasil = scrape_semua_berita()\n",
    "    if df_hasil is not None:\n",
    "        pd.set_option('display.max_colwidth', 100)\n",
    "        print(\"\\nContoh hasil data:\")\n",
    "        print(df_hasil.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140c532b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_berita</th>\n",
       "      <th>kategori</th>\n",
       "      <th>judul</th>\n",
       "      <th>isi_berita</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153055</td>\n",
       "      <td>Jatim</td>\n",
       "      <td>Ada Santri yang Diduga Dihukum untuk Cor Bangunan Musala Ambruk Ponpes Al Khoziny</td>\n",
       "      <td>SIDOARJO,BANGSAONLINE.com- Proses pencarian korban para santri tertimbun reruntuhan musala ambru...</td>\n",
       "      <td>https://bangsaonline.com/berita/153055/ada-santri-yang-diduga-dihukum-untuk-cor-bangunan-musala-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153054</td>\n",
       "      <td>Jatim</td>\n",
       "      <td>Warga Dringu Lapor Dugaan Penipuan Kavling, Polres Probolinggo Kota Siap Tindaklanjuti</td>\n",
       "      <td>PROBOLINGGO, BANGSAONLINE.com- Polres Probolinggo Kota menerima laporan dari warga Desa/Kecamata...</td>\n",
       "      <td>https://bangsaonline.com/berita/153054/warga-dringu-lapor-dugaan-penipuan-kavling-polres-proboli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153053</td>\n",
       "      <td>Jatim</td>\n",
       "      <td>Hadiri Pengukuhan Pengurus Kormi Kota Kediri, Gus Qowim Dorong Olahraga untuk Semua Usia</td>\n",
       "      <td>KOTA KEDIRI, BANGSAONLINE.com- Wakil Wali Kota Kediri, Qowimuddin Thoha atau yang akrab disapa G...</td>\n",
       "      <td>https://bangsaonline.com/berita/153053/hadiri-pengukuhan-pengurus-kormi-kota-kediri-gus-qowim-do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153052</td>\n",
       "      <td>Jatim</td>\n",
       "      <td>Datang ke RS William Booth Perpanjang Rujukan Anak, Pria di Surabaya Malah Curi Motor</td>\n",
       "      <td>SURABAYA,BANGSAONLINE.com- Polsek Wonokromo  menangkap pelaku pencurian motor di area parkir Rum...</td>\n",
       "      <td>https://bangsaonline.com/berita/153052/datang-ke-rs-william-booth-perpanjang-rujukan-anak-pria-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153050</td>\n",
       "      <td>Jatim</td>\n",
       "      <td>Polwan Polresta Sidoarjo Layani Keluarga Korban Musala Ambruk Ponpes Al Khoziny</td>\n",
       "      <td>SIDOARJO,BANGSAONLINE.com- Polwan Polresta Sidoarjo memberikan pelayanan bagi keluarga korban tr...</td>\n",
       "      <td>https://bangsaonline.com/berita/153050/polwan-polresta-sidoarjo-layani-keluarga-korban-musala-am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_berita kategori  \\\n",
       "0    153055    Jatim   \n",
       "1    153054    Jatim   \n",
       "2    153053    Jatim   \n",
       "3    153052    Jatim   \n",
       "4    153050    Jatim   \n",
       "\n",
       "                                                                                      judul  \\\n",
       "0         Ada Santri yang Diduga Dihukum untuk Cor Bangunan Musala Ambruk Ponpes Al Khoziny   \n",
       "1    Warga Dringu Lapor Dugaan Penipuan Kavling, Polres Probolinggo Kota Siap Tindaklanjuti   \n",
       "2  Hadiri Pengukuhan Pengurus Kormi Kota Kediri, Gus Qowim Dorong Olahraga untuk Semua Usia   \n",
       "3     Datang ke RS William Booth Perpanjang Rujukan Anak, Pria di Surabaya Malah Curi Motor   \n",
       "4           Polwan Polresta Sidoarjo Layani Keluarga Korban Musala Ambruk Ponpes Al Khoziny   \n",
       "\n",
       "                                                                                            isi_berita  \\\n",
       "0  SIDOARJO,BANGSAONLINE.com- Proses pencarian korban para santri tertimbun reruntuhan musala ambru...   \n",
       "1  PROBOLINGGO, BANGSAONLINE.com- Polres Probolinggo Kota menerima laporan dari warga Desa/Kecamata...   \n",
       "2  KOTA KEDIRI, BANGSAONLINE.com- Wakil Wali Kota Kediri, Qowimuddin Thoha atau yang akrab disapa G...   \n",
       "3  SURABAYA,BANGSAONLINE.com- Polsek Wonokromo  menangkap pelaku pencurian motor di area parkir Rum...   \n",
       "4  SIDOARJO,BANGSAONLINE.com- Polwan Polresta Sidoarjo memberikan pelayanan bagi keluarga korban tr...   \n",
       "\n",
       "                                                                                                  link  \n",
       "0  https://bangsaonline.com/berita/153055/ada-santri-yang-diduga-dihukum-untuk-cor-bangunan-musala-...  \n",
       "1  https://bangsaonline.com/berita/153054/warga-dringu-lapor-dugaan-penipuan-kavling-polres-proboli...  \n",
       "2  https://bangsaonline.com/berita/153053/hadiri-pengukuhan-pengurus-kormi-kota-kediri-gus-qowim-do...  \n",
       "3  https://bangsaonline.com/berita/153052/datang-ke-rs-william-booth-perpanjang-rujukan-anak-pria-d...  \n",
       "4  https://bangsaonline.com/berita/153050/polwan-polresta-sidoarjo-layani-keluarga-korban-musala-am...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hasil.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}