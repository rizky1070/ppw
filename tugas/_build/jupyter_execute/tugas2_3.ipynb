{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085e27af",
   "metadata": {},
   "source": [
    "# Crawling Berita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb1f771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencari kategori berita di bangsaonline.com...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ditemukan 37 kategori berita valid.\n",
      "\n",
      "--- Scraping Kategori: JATIM ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Festival Kopi Quds Royal Hotel Surabaya Meriahkan Akhir Tahu...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: PT Freeport Gelar Pelatihan Apartemen Kepiting sebagai Solus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM METRO ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Diabetes dan Hipertensi Meningkat, BPJS Kesehatan Sidoarjo G...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Pramuka Jatim Salurkan Bantuan Rp605 Juta untuk Bencana di S...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM TENGAH ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Mubes, Hari Terpilih Jadi Ketua FPRB Kabupaten Kediri Period...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Dirbimas Ditjenpas Resmikan Griya Abipraya Kahuripan Kediri...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM UTARA ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Cegah Korupsi, Pemkab Lamongan Terapkan Strategi Digitalisas...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Bupati Gresik Lantik Kades Wadak Kidul PAW, Ingatkan soal De...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM SELATAN ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Meski Sudah Sidang dan Kapolres Minta Maaf, Salah Tangkap Po...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Berhasil Turunkan Angka Stunting, Pemkot Batu Raih Pengharga...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM TIMUR ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Musyawarah Ganti Rugi Tol Pandaan-Malang Digelar di Pasuruan...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Pakai Kostum Badut, Maling Motor di Purwosari Pasuruan Babak...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM BARAT ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Pemkab Madiun Gandeng Kejari Sosialisasikan Penerapan KUHP N...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Tiket Kereta Nataru Daop 7 Madiun Masih Tersedia, Penjualan ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: JATIM MADURA ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/2) Berhasil scrape: Bupati Pamekasan Lantik 4.161 P3K Paruh Waktu, Harap Kerja K...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/2) Berhasil scrape: Pemkab Pamekasan Selamatkan 86 Ribu Warga dari Ancaman Putus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Kategori: NASIONAL ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 149\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# --- Untuk Menjalankan Seluruh Proses Scraping ---\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     df_hasil \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_semua_berita\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df_hasil \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m         pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 65\u001b[0m, in \u001b[0;36mscrape_semua_berita\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m response_kategori \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url_kategori, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     64\u001b[0m response_kategori\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m---> 65\u001b[0m soup_kategori \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_kategori\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# --- SELECTOR DIKEMBALIKAN SESUAI PERMINTAAN ---\u001b[39;00m\n\u001b[0;32m     68\u001b[0m list_artikel \u001b[38;5;241m=\u001b[39m soup_kategori\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh3.entry-title a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\bs4\\__init__.py:473\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 473\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\bs4\\__init__.py:658\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkup \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 658\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\bs4\\builder\\_htmlparser.py:467\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    464\u001b[0m parser \u001b[38;5;241m=\u001b[39m BeautifulSoupHTMLParser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     parser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# html.parser raises AssertionError in rare cases to\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;66;03m# indicate a fatal problem with the markup, especially\u001b[39;00m\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;66;03m# when there's an error in the doctype declaration.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\html\\parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\html\\parser.py:172\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    170\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_starttag(i)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[1;32m--> 172\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_endtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<!--\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[0;32m    174\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_comment(i)\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\html\\parser.py:420\u001b[0m, in \u001b[0;36mHTMLParser.parse_endtag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_data(rawdata[i:gtpos])\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m gtpos\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_endtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_cdata_mode()\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gtpos\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\bs4\\builder\\_htmlparser.py:220\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_endtag\u001b[1;34m(self, name, check_already_closed)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malready_closed_empty_element\u001b[38;5;241m.\u001b[39mremove(name)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_endtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\bs4\\__init__.py:1063\u001b[0m, in \u001b[0;36mBeautifulSoup.handle_endtag\u001b[1;34m(self, name, nsprefix)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# print(\"End tag: \" + name)\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n\u001b[1;32m-> 1063\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popToTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsprefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\bs4\\__init__.py:981\u001b[0m, in \u001b[0;36mBeautifulSoup._popToTag\u001b[1;34m(self, name, nsprefix, inclusivePop)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m t\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mand\u001b[39;00m nsprefix \u001b[38;5;241m==\u001b[39m t\u001b[38;5;241m.\u001b[39mprefix:\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inclusivePop:\n\u001b[1;32m--> 981\u001b[0m         most_recently_popped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    983\u001b[0m most_recently_popped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopTag()\n",
      "File \u001b[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\bs4\\__init__.py:802\u001b[0m, in \u001b[0;36mBeautifulSoup.popTag\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreserve_whitespace_tag_stack\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m tag \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreserve_whitespace_tag_stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    800\u001b[0m ):\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreserve_whitespace_tag_stack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m--> 802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstring_container_stack \u001b[38;5;129;01mand\u001b[39;00m tag \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstring_container_stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstring_container_stack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# print(\"Pop\", tag.name)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "def dapatkan_kategori_berita():\n",
    "    \"\"\"\n",
    "    Fungsi untuk mengambil daftar semua kategori berita dari menu navigasi\n",
    "    website bangsaonline.com.\n",
    "    \"\"\"\n",
    "    print(\"Mencari kategori berita di bangsaonline.com...\")\n",
    "    kategori_list = {}\n",
    "    url_home = \"https://bangsaonline.com/\"\n",
    "    try:\n",
    "        response = requests.get(url_home, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        nav_menu = soup.select_one('ul#nav')\n",
    "        if not nav_menu:\n",
    "            print(\"Menu navigasi (ul#nav) tidak ditemukan.\")\n",
    "            return {}\n",
    "\n",
    "        for item in nav_menu.find_all(\"a\"):\n",
    "            href = item.get(\"href\")\n",
    "            nama_kategori = item.get_text(strip=True)\n",
    "            \n",
    "            if href and nama_kategori:\n",
    "                path_parts = urlparse(href).path.strip(\"/\").split(\"/\")\n",
    "                \n",
    "                if len(path_parts) == 2 and path_parts[0] == 'kanal':\n",
    "                    url_lengkap = urljoin(url_home, href)\n",
    "                    if nama_kategori not in kategori_list:\n",
    "                        kategori_list[nama_kategori] = url_lengkap\n",
    "\n",
    "        print(f\"Ditemukan {len(kategori_list)} kategori berita valid.\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Gagal mengambil daftar kategori berita: {e}\")\n",
    "        \n",
    "    return kategori_list\n",
    "\n",
    "def scrape_semua_berita():\n",
    "    \"\"\"\n",
    "    Fungsi utama untuk melakukan scraping berita dari semua kategori yang ditemukan.\n",
    "    \"\"\"\n",
    "    daftar_kategori = dapatkan_kategori_berita()\n",
    "\n",
    "    if not daftar_kategori:\n",
    "        print(\"Tidak ada kategori yang bisa di-scrape. Program berhenti.\")\n",
    "        return\n",
    "\n",
    "    data_berita = []\n",
    "    scraped_links = set()\n",
    "    url_home = \"https://bangsaonline.com/\"\n",
    "\n",
    "    for nama_kategori, url_kategori in daftar_kategori.items():\n",
    "        print(f\"\\n--- Scraping Kategori: {nama_kategori.upper()} ---\")\n",
    "        artikel_diambil = 0\n",
    "        \n",
    "        try:\n",
    "            response_kategori = requests.get(url_kategori, timeout=10)\n",
    "            response_kategori.raise_for_status()\n",
    "            soup_kategori = BeautifulSoup(response_kategori.text, \"html.parser\")\n",
    "\n",
    "            # --- SELECTOR DIKEMBALIKAN SESUAI PERMINTAAN ---\n",
    "            list_artikel = soup_kategori.select(\"h3.entry-title a\")\n",
    "            \n",
    "            if not list_artikel:\n",
    "                print(\"Tidak ada tautan artikel ditemukan di halaman ini.\")\n",
    "                continue\n",
    "\n",
    "            for artikel in list_artikel:\n",
    "                # Anda bisa mengubah angka 2 ini jika ingin scrape lebih banyak per kategori\n",
    "                if artikel_diambil >= 2:\n",
    "                    break\n",
    "                \n",
    "                link_parsial = artikel.get(\"href\")\n",
    "                if not link_parsial:\n",
    "                    continue\n",
    "                \n",
    "                link = urljoin(url_home, link_parsial)\n",
    "                \n",
    "                if link in scraped_links:\n",
    "                    continue\n",
    "\n",
    "                scraped_links.add(link)\n",
    "\n",
    "                try:\n",
    "                    resp_detail = requests.get(link, timeout=10)\n",
    "                    resp_detail.raise_for_status()\n",
    "                    soup_detail = BeautifulSoup(resp_detail.text, \"html.parser\")\n",
    "\n",
    "                    # --- SELECTOR DIKEMBALIKAN SESUAI PERMINTAAN ---\n",
    "                    judul_element = soup_detail.select_one(\"h1.entry-title\")\n",
    "                    konten_berita = soup_detail.select_one(\"div.post\")\n",
    "                    \n",
    "                    if judul_element and konten_berita:\n",
    "                        judul = judul_element.get_text(strip=True)\n",
    "                        \n",
    "                        id_berita = None\n",
    "                        try:\n",
    "                            path_parts = urlparse(link).path.strip(\"/\").split(\"/\")\n",
    "                            if len(path_parts) > 1 and path_parts[1].isdigit():\n",
    "                                id_berita = path_parts[1]\n",
    "                        except (IndexError, AttributeError):\n",
    "                            id_berita = None\n",
    "                        \n",
    "                        for unwanted in konten_berita.select(\"div.baca-juga\"):\n",
    "                            unwanted.decompose()\n",
    "                        \n",
    "                        paragraf = [p.get_text(strip=True) for p in konten_berita.select(\"p\")]\n",
    "                        isi = \" \".join(paragraf)\n",
    "\n",
    "                        if isi:\n",
    "                            data_berita.append({\n",
    "                                \"id_berita\": id_berita,\n",
    "                                \"kategori\": nama_kategori,\n",
    "                                \"judul\": judul,\n",
    "                                \"isi_berita\": isi,\n",
    "                                \"link\": link\n",
    "                            })\n",
    "                            artikel_diambil += 1\n",
    "                            print(f\"({artikel_diambil}/2) Berhasil scrape: {judul[:60]}...\")\n",
    "                    \n",
    "                    time.sleep(1)\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"  -> Gagal mengambil detail dari {link}: {e}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Gagal memproses halaman kategori {url_kategori}: {e}\")\n",
    "            \n",
    "    if not data_berita:\n",
    "        print(\"\\nTidak ada berita yang berhasil di-scrape.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(data_berita)\n",
    "    df = df[[\"id_berita\", \"kategori\", \"judul\", \"isi_berita\", \"link\"]]\n",
    "    \n",
    "    df.to_csv(\"hasil_scraping_berita_bangsaonline.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\n✅ Proses scraping selesai. {len(df)} berita disimpan ke 'hasil_scraping_berita_bangsaonline.csv'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- Untuk Menjalankan Seluruh Proses Scraping ---\n",
    "if __name__ == \"__main__\":\n",
    "    df_hasil = scrape_semua_berita()\n",
    "    if df_hasil is not None:\n",
    "        pd.set_option('display.max_colwidth', 100)\n",
    "        print(\"\\nContoh hasil data:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140c532b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_berita</th>\n",
       "      <th>kategori</th>\n",
       "      <th>judul</th>\n",
       "      <th>isi_berita</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152149</td>\n",
       "      <td>Jatim</td>\n",
       "      <td>Judi Sabung Ayam di Pamekasan Digerebek, 6 Orang Diamankan</td>\n",
       "      <td>PAMEKASAN, BANGSAONLINE.com- Satreskrim Polres Pamekasan menggerebek arena judi sabung ayam di D...</td>\n",
       "      <td>https://bangsaonline.com/berita/152149/judi-sabung-ayam-di-pamekasan-digerebek-6-orang-diamankan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152148</td>\n",
       "      <td>Jatim</td>\n",
       "      <td>Pemilik Ladang Ganja di Blitar Akui Jual Ganja Kering Rp5 Juta Perkilogram</td>\n",
       "      <td>BLITAR, BANGSAONLINE.com- Pemilik ladang ganja, SA (38), warga Desa Krisik, Kecamatan Gandusari,...</td>\n",
       "      <td>https://bangsaonline.com/berita/152148/pemilik-ladang-ganja-di-blitar-akui-jual-ganja-kering-rp5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152132</td>\n",
       "      <td>Jatim Metro</td>\n",
       "      <td>Permudah Warga Urus Surat Secara Digital, Pemdes Banjarsari Luncurkan Aplikasi PAOD</td>\n",
       "      <td>SIDOARJO, BANGSAONLINE.com- Pemerintah Desa (Pemdes) Banjarsari, Kecamatan Buduran, melakukan te...</td>\n",
       "      <td>https://bangsaonline.com/berita/152132/permudah-warga-urus-surat-secara-digital-pemdes-banjarsar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152118</td>\n",
       "      <td>Jatim Metro</td>\n",
       "      <td>Fesyar 2025 Siap Digelar di Surabaya, Gubernur Khofifah Optimistis Jatim Jadi Pusat Ekonomi Syariah</td>\n",
       "      <td>SURABAYA, BANGSAONLINE.com- Gubernur Khofifah menyatakan optimisme tinggi terhadap penyelenggara...</td>\n",
       "      <td>https://bangsaonline.com/berita/152118/fesyar-2025-siap-digelar-di-surabaya-gubernur-khofifah-op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152142</td>\n",
       "      <td>Jatim Tengah</td>\n",
       "      <td>Wali Kota Kediri dan Staf Ahli Bidang Ekonomi Maritim Kemenko Pangan Tinjau Koperasi Merah Putih</td>\n",
       "      <td>KOTA KEDIRI, BANGSAONLINE.com- Wali Kota Kediri, Vinanda Prameswati, bersama Staf Ahli Bidang Ek...</td>\n",
       "      <td>https://bangsaonline.com/berita/152142/wali-kota-kediri-dan-staf-ahli-bidang-ekonomi-maritim-kem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_berita      kategori  \\\n",
       "0    152149         Jatim   \n",
       "1    152148         Jatim   \n",
       "2    152132   Jatim Metro   \n",
       "3    152118   Jatim Metro   \n",
       "4    152142  Jatim Tengah   \n",
       "\n",
       "                                                                                                 judul  \\\n",
       "0                                           Judi Sabung Ayam di Pamekasan Digerebek, 6 Orang Diamankan   \n",
       "1                           Pemilik Ladang Ganja di Blitar Akui Jual Ganja Kering Rp5 Juta Perkilogram   \n",
       "2                  Permudah Warga Urus Surat Secara Digital, Pemdes Banjarsari Luncurkan Aplikasi PAOD   \n",
       "3  Fesyar 2025 Siap Digelar di Surabaya, Gubernur Khofifah Optimistis Jatim Jadi Pusat Ekonomi Syariah   \n",
       "4     Wali Kota Kediri dan Staf Ahli Bidang Ekonomi Maritim Kemenko Pangan Tinjau Koperasi Merah Putih   \n",
       "\n",
       "                                                                                            isi_berita  \\\n",
       "0  PAMEKASAN, BANGSAONLINE.com- Satreskrim Polres Pamekasan menggerebek arena judi sabung ayam di D...   \n",
       "1  BLITAR, BANGSAONLINE.com- Pemilik ladang ganja, SA (38), warga Desa Krisik, Kecamatan Gandusari,...   \n",
       "2  SIDOARJO, BANGSAONLINE.com- Pemerintah Desa (Pemdes) Banjarsari, Kecamatan Buduran, melakukan te...   \n",
       "3  SURABAYA, BANGSAONLINE.com- Gubernur Khofifah menyatakan optimisme tinggi terhadap penyelenggara...   \n",
       "4  KOTA KEDIRI, BANGSAONLINE.com- Wali Kota Kediri, Vinanda Prameswati, bersama Staf Ahli Bidang Ek...   \n",
       "\n",
       "                                                                                                  link  \n",
       "0     https://bangsaonline.com/berita/152149/judi-sabung-ayam-di-pamekasan-digerebek-6-orang-diamankan  \n",
       "1  https://bangsaonline.com/berita/152148/pemilik-ladang-ganja-di-blitar-akui-jual-ganja-kering-rp5...  \n",
       "2  https://bangsaonline.com/berita/152132/permudah-warga-urus-surat-secara-digital-pemdes-banjarsar...  \n",
       "3  https://bangsaonline.com/berita/152118/fesyar-2025-siap-digelar-di-surabaya-gubernur-khofifah-op...  \n",
       "4  https://bangsaonline.com/berita/152142/wali-kota-kediri-dan-staf-ahli-bidang-ekonomi-maritim-kem...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hasil.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}