Traceback (most recent call last):
  File "C:\laragon\bin\python\python-3.10\lib\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\laragon\bin\python\python-3.10\lib\site-packages\nbclient\client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\Users\Rizky\AppData\Roaming\Python\Python310\site-packages\jupyter_core\utils\__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
  File "C:\laragon\bin\python\python-3.10\lib\asyncio\base_events.py", line 646, in run_until_complete
    return future.result()
  File "C:\laragon\bin\python\python-3.10\lib\site-packages\nbclient\client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "C:\laragon\bin\python\python-3.10\lib\site-packages\nbclient\client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\laragon\bin\python\python-3.10\lib\site-packages\nbclient\client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import fitz  # PyMuPDF
import nltk
import networkx as nx
import matplotlib.pyplot as plt
import re
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
from collections import defaultdict
import pymupdf4llm
import pandas as pd # Import pandas for matrix display
import numpy as np # Import numpy

# --- Konfigurasi Awal ---
# Mengunduh resource NLTK yang diperlukan
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')

def main():
    pdf_path = "Nasi_goreng_food_and_wine_pairing_Fried_rice_food_.pdf"

    # ==========================================
    # TAHAP 1: Ekstrak Text dari PDF
    # ==========================================
    print(f"--- 1. Mengekstrak teks dari {pdf_path} ---")
    text_content = extract_text_from_pdf(pdf_path)
    print(f"Berhasil mengekstrak {len(text_content)} karakter.")

    # ==========================================
    # TAHAP 2: Ekstrak Kalimat menggunakan NLTK
    # ==========================================
    print("\n--- 2. Mengekstrak kalimat & Preprocessing ---")
    sentences = sent_tokenize(text_content)
    print(f"Ditemukan {len(sentences)} kalimat mentah.")

    # Tambahan: Menampilkan beberapa kalimat asli
    print("\nContoh 5 Kalimat Asli:")
    for i, sentence in enumerate(sentences[:5]):
        print(f"  {i+1}. {sentence.strip()}")

    # Preprocessing (Membersihkan teks untuk hasil graph yang lebih baik)
    # Kita menghapus stopwords (kata umum seperti 'dan', 'yang', 'the')
    clean_sentences_tokens = preprocess_text(sentences)
    print(f"Ditemukan {len(clean_sentences_tokens)} kalimat setelah preprocessing.")

    # Tambahan: Menampilkan beberapa kalimat hasil tokenisasi
    print("\nContoh 5 Kalimat Hasil Tokenisasi (setelah Preprocessing):")
    for i, tokens in enumerate(clean_sentences_tokens[:5]):
        print(f"  {i+1}. {' '.join(tokens)}")

    # ==========================================
    # TAHAP 3: Membuat Graph menggunakan Co-occurrence Matrix
    # ==========================================
    print("\n--- 3. Membangun Word Graph (Co-occurrence) ---")
    # Menggunakan Window Size = 2
    window_size = 2
    G = build_co_occurrence_graph(clean_sentences_tokens, window_size)
    print(f"Graph terbentuk dengan {G.number_of_nodes()} node (kata) dan {G.number_of_edges()} edge (hubungan).")

    print("\nContoh 10 Pasangan Kata Co-occurrence Teratas:")
    # Mengurutkan edge berdasarkan weight (co-occurrence count) secara menurun
    sorted_edges = sorted(G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)
    for i, (u, v, data) in enumerate(sorted_edges[:10]):
        print(f"  {i+1}. ('{u}', '{v}'): {data['weight']} kali")

    # ==========================================
    # TAHAP 4: Analisa PageRank
    # ==========================================
    print("\n--- 4. Menghitung PageRank ---")
    pagerank_scores = nx.pagerank(G, weight='weight')

    # Mengurutkan kata berdasarkan skor tertinggi
    sorted_ranking = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)

    print("\nTop 10 Kata Kunci (Berdasarkan PageRank):")
    for i, (word, score) in enumerate(sorted_ranking[:10], 1):
        print(f"{i}. {word}: {score:.4f}")

    # ==========================================
    # MENAMPILKAN CO-OCCURRENCE MATRIX
    # ==========================================
    print("\n--- Full Co-occurrence Matrix ---")
    all_words_for_matrix = list(G.nodes())
    co_occurrence_matrix = pd.DataFrame(0, index=all_words_for_matrix, columns=all_words_for_matrix, dtype=int)

    for u, v, data in G.edges(data=True):
        co_occurrence_matrix.loc[u, v] = data['weight']
        co_occurrence_matrix.loc[v, u] = data['weight'] # Matriks simetris
    display(co_occurrence_matrix)


    # ==========================================
    # VISUALISASI
    # ==========================================
    visualize_graph(G)

# --- Fungsi Pendukung ---

def extract_text_from_pdf(filepath):
    """
    Ekstrak teks mentah dari PDF menggunakan PyMuPDF (fitz).
    Diperbarui untuk menggunakan pymupdf4llm.to_markdown().
    """
    doc = fitz.open(filepath)
    text = pymupdf4llm.to_markdown(doc)
    doc.close()
    return text

def preprocess_text(sentences):
    """
    Membersihkan kalimat: lowercase, hapus tanda baca, hapus stopwords.
    """
    cleaned_tokens_list = []

    # Gabungan stopword Indonesia dan Inggris karena dokumen bilingual
    stop_words = set(stopwords.words('indonesian') + stopwords.words('english'))

    for sentence in sentences:
        # Hapus karakter non-huruf dan ubah ke huruf kecil
        sentence = re.sub(r'[^a-zA-Z\s]', '', sentence).lower()
        tokens = word_tokenize(sentence)

        # Filter stopwords dan kata pendek
        filtered_tokens = [w for w in tokens if w not in stop_words and len(w) > 2]

        if filtered_tokens:
            cleaned_tokens_list.append(filtered_tokens)

    return cleaned_tokens_list

def build_co_occurrence_graph(tokens_list, window_size=2):
    """
    Membangun Graph dari co-occurrence matrix.
    Node = Kata, Edge = Kemunculan bersama dalam window size.
    """
    d = defaultdict(int)
    vocab = set()

    for tokens in tokens_list:
        for i in range(len(tokens)):
            token = tokens[i]
            vocab.add(token)

            for j in range(1, window_size + 1):
                if i + j < len(tokens):
                    next_token = tokens[i + j]
                    # Urutkan pasangan agar (A, B) sama dengan (B, A) (Undirected Graph)
                    pair = tuple(sorted((token, next_token)))
                    d[pair] += 1

    # Buat Graph menggunakan NetworkX
    G = nx.Graph()
    for (w1, w2), count in d.items():
        G.add_edge(w1, w2, weight=count)

    return G

def visualize_graph(G, top_nodes_data=None):
    plt.figure(figsize=(15, 15))  # 1. Perbesar ukuran kanvas

    graph_to_draw = G

    # Cek statistik graph
    num_nodes = graph_to_draw.number_of_nodes()
    num_edges = graph_to_draw.number_of_edges()
    print(f"Menampilkan Graph: {num_nodes} node, {num_edges} edge")

    if num_edges == 0:
        print("PERINGATAN: Graph tidak memiliki garis penghubung!")
        return

    # 2. Atur tata letak (Layout)
    # k=0.5 memberikan jarak yang cukup antar node (semakin kecil k, semakin rapat)
    pos = nx.spring_layout(graph_to_draw, k=0.5, iterations=50, seed=42)

    # 3. Tentukan ukuran node berdasarkan jumlah kata
    # Jika kata sedikit (<50), node besar (1000). Jika banyak, node kecil (100-300).
    dynamic_node_size = 300 if num_nodes > 50 else 1000
    dynamic_font_size = 8 if num_nodes > 50 else 10

    # Gambar Nodes
    nx.draw_networkx_nodes(graph_to_draw, pos, node_size=dynamic_node_size, node_color='lightgreen', alpha=0.9)

    # Gambar Edges (Garis)
    # width=1.0 agar garis jelas, alpha=0.6 agar tidak terlalu pekat jika tumpang tindih
    nx.draw_networkx_edges(graph_to_draw, pos, width=1.0, alpha=0.6, edge_color='gray')

    # Gambar Label
    nx.draw_networkx_labels(graph_to_draw, pos, font_size=dynamic_font_size)

    plt.title(f"Full Word Graph ({num_nodes} words)", fontsize=15)
    plt.axis('off')
    plt.show()
if __name__ == "__main__":
    main()
------------------

----- stdout -----
Consider using the pymupdf_layout package for a greatly improved page layout analysis.
----- stderr -----
[nltk_data] Downloading package punkt to
[nltk_data]     C:\Users\Rizky\AppData\Roaming\nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package stopwords to
[nltk_data]     C:\Users\Rizky\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package punkt_tab to
[nltk_data]     C:\Users\Rizky\AppData\Roaming\nltk_data...
[nltk_data]   Package punkt_tab is already up-to-date!
----- stdout -----
--- 1. Mengekstrak teks dari Nasi_goreng_food_and_wine_pairing_Fried_rice_food_.pdf ---
------------------

[1;31m---------------------------------------------------------------------------[0m
[1;31mFileNotFoundError[0m                         Traceback (most recent call last)
[1;32m~\AppData\Local\Temp\ipykernel_32548\2940036121.py[0m in [0;36m?[1;34m()[0m
[0;32m    191[0m     [0mplt[0m[1;33m.[0m[0mtitle[0m[1;33m([0m[1;34mf"Full Word Graph ({num_nodes} words)"[0m[1;33m,[0m [0mfontsize[0m[1;33m=[0m[1;36m15[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0;32m    192[0m     [0mplt[0m[1;33m.[0m[0maxis[0m[1;33m([0m[1;34m'off'[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0;32m    193[0m     [0mplt[0m[1;33m.[0m[0mshow[0m[1;33m([0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0;32m    194[0m [1;32mif[0m [0m__name__[0m [1;33m==[0m [1;34m"__main__"[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[1;32m--> 195[1;33m     [0mmain[0m[1;33m([0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m
[1;32m~\AppData\Local\Temp\ipykernel_32548\2940036121.py[0m in [0;36m?[1;34m()[0m
[0;32m     22[0m     [1;31m# ==========================================[0m[1;33m[0m[1;33m[0m[0m
[0;32m     23[0m     [1;31m# TAHAP 1: Ekstrak Text dari PDF[0m[1;33m[0m[1;33m[0m[0m
[0;32m     24[0m     [1;31m# ==========================================[0m[1;33m[0m[1;33m[0m[0m
[0;32m     25[0m     [0mprint[0m[1;33m([0m[1;34mf"--- 1. Mengekstrak teks dari {pdf_path} ---"[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[1;32m---> 26[1;33m     [0mtext_content[0m [1;33m=[0m [0mextract_text_from_pdf[0m[1;33m([0m[0mpdf_path[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m     27[0m     [0mprint[0m[1;33m([0m[1;34mf"Berhasil mengekstrak {len(text_content)} karakter."[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0;32m     28[0m [1;33m[0m[0m
[0;32m     29[0m     [1;31m# ==========================================[0m[1;33m[0m[1;33m[0m[0m

[1;32m~\AppData\Local\Temp\ipykernel_32548\2940036121.py[0m in [0;36m?[1;34m(filepath)[0m
[0;32m    100[0m     """
[0;32m    101[0m     [0mEkstrak[0m [0mteks[0m [0mmentah[0m [0mdari[0m [0mPDF[0m [0mmenggunakan[0m [0mPyMuPDF[0m [1;33m([0m[0mfitz[0m[1;33m)[0m[1;33m.[0m[1;33m[0m[1;33m[0m[0m
[0;32m    102[0m     [0mDiperbarui[0m [0muntuk[0m [0mmenggunakan[0m [0mpymupdf4llm[0m[1;33m.[0m[0mto_markdown[0m[1;33m([0m[1;33m)[0m[1;33m.[0m[1;33m[0m[1;33m[0m[0m
[0;32m    103[0m     """
[1;32m--> 104[1;33m     [0mdoc[0m [1;33m=[0m [0mfitz[0m[1;33m.[0m[0mopen[0m[1;33m([0m[0mfilepath[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    105[0m     [0mtext[0m [1;33m=[0m [0mpymupdf4llm[0m[1;33m.[0m[0mto_markdown[0m[1;33m([0m[0mdoc[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0;32m    106[0m     [0mdoc[0m[1;33m.[0m[0mclose[0m[1;33m([0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0;32m    107[0m     [1;32mreturn[0m [0mtext[0m[1;33m[0m[1;33m[0m[0m

[1;32mC:\laragon\bin\python\python-3.10\lib\site-packages\pymupdf\__init__.py[0m in [0;36m?[1;34m(self, filename, stream, filetype, rect, width, height, fontsize)[0m
[0;32m   3061[0m                     [0mself[0m[1;33m.[0m[0mpage_count2[0m [1;33m=[0m [0mextra[0m[1;33m.[0m[0mpage_count_pdf[0m[1;33m[0m[1;33m[0m[0m
[0;32m   3062[0m                 [1;32melse[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m   3063[0m                     [0mself[0m[1;33m.[0m[0mpage_count2[0m [1;33m=[0m [0mextra[0m[1;33m.[0m[0mpage_count_fz[0m[1;33m[0m[1;33m[0m[0m
[0;32m   3064[0m         [1;32mfinally[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[1;32m-> 3065[1;33m             [0mJM_mupdf_show_errors[0m [1;33m=[0m [0mJM_mupdf_show_errors_old[0m[1;33m[0m[1;33m[0m[0m
[0m
[1;31mFileNotFoundError[0m: no such file: 'Nasi_goreng_food_and_wine_pairing_Fried_rice_food_.pdf'

