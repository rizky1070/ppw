{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e5a919",
   "metadata": {},
   "source": [
    "# CBOW PTA Manajemen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c044a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 1: MEMPERSIAPKAN CORPUS ---\n",
      "Proses persiapan corpus selesai.\n",
      "Berikut adalah contoh 1 abstrak yang sudah diubah menjadi daftar token:\n",
      "['abstrak', 'satiyah', 'pengaruh', 'faktorfaktor', 'latih', 'kembang', 'produktivitas', 'kerja', 'dinas', 'laut', 'ikan', 'bangkal', 'bawah', 'bimbing', 'drahjsanugrahini', 'irawatimm', 'helm', 'buyung', 'auliasstsemmt', 'upaya', 'tingkat', 'produktivitas', 'kerja', 'mudah', 'salah', 'usaha', 'produktivitas', 'tingkat', 'terap', 'program', 'latih', 'kembang', 'sumber', 'daya', 'manusia', 'sdm', 'laksana', 'instansi', 'produktivitas', 'capai', 'tingkat', 'mampu', 'pegawai', 'efektif', 'efisien', 'latih', 'pengembnagan', 'harap', 'pegawai', 'sesuai', 'kebutuhankebutuhan', 'sikap', 'tingkah', 'laku', 'terampil', 'tahu', 'sesuai', 'tuntut', 'ubah', 'latih', 'kembang', 'pegawai', 'dukung', 'cipta', 'suasana', 'kerja', 'kondusif', 'instansi', 'produktivitas', 'kerja', 'tingkat', 'tuju', 'teliti', 'pengaruh', 'faktorfaktor', 'latih', 'kembang', 'produktivitas', 'kerja', 'dinas', 'laut', 'ikan', 'bangkal', 'ukur', 'menganalisa', 'hubung', 'variabel', 'teliti', 'dekat', 'observasional', 'analitik', 'amat', 'langsung', 'responden', 'sebar', 'kuisioner', 'analis', 'teliti', 'teliti', 'populasi', 'responden', 'sampel', 'olah', 'spss', 'versi', 'analis', 'metode', 'statistik', 'metode', 'non', 'probality', 'sampling', 'simple', 'random', 'sampling', 'simpul', 'teliti', 'a', 'faktorfaktor', 'latih', 'kembang', 'beda', 'individu', 'pegawai', 'x', 'hubung', 'analisis', 'jabat', 'x', 'motivasi', 'x', 'partisipasi', 'aktif', 'x', 'seleksi', 'serta', 'x', 'seleksi', 'instruktur', 'x', 'metode', 'latih', 'kembang', 'x', 'pengaruh', 'simultan', 'produktivitas', 'kerja', 'pegawai', 'dinas', 'laut', 'ikan', 'kabupaten', 'bangkal', 'bukti', 'nilai', 'koefisien', 'determinasi', 'ganda', 'r', 'r', 'square', 'fhitung', 'ftabel', 'b', 'faktor', 'hubung', 'analisis', 'jabat', 'pengaruh', 'parsial', 'produktivitas', 'kerja', 'pegawai', 'dinas', 'laut', 'ikan', 'kabupaten', 'bangkal', 'uji', 'hipotesis', 'variabel', 'motivasi', 'x', 'bukti', 'nilai', 'thitung', 'seleksi', 'serta', 'x', 'pengaruh', 'dominan', 'produktivitas', 'kerja', 'pegawai', 'instansi', 'dinas', 'laut', 'ikan', 'bangkal', 'kunci', 'dinas', 'laut', 'ikan', 'faktorfaktor', 'latih', 'kembang', 'produktivitas', 'kerja']\n"
     ]
    }
   ],
   "source": [
    "# --- Import semua library yang dibutuhkan ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from gensim.models import Word2Vec\n",
    "import logging # Untuk menampilkan log proses training\n",
    "\n",
    "# --- 1. Persiapan Corpus ---\n",
    "print(\"--- TAHAP 1: MEMPERSIAPKAN CORPUS ---\")\n",
    "# Load data dari file CSV hasil preprocessing Anda\n",
    "df = pd.read_csv('hasil_preprocessing_manajemen.csv')\n",
    "\n",
    "# Mengubah kolom 'hasil_preprocessing' dari string menjadi list python sungguhan\n",
    "df['tokens'] = df['hasil_preprocessing'].apply(ast.literal_eval)\n",
    "corpus = df['tokens'].tolist()\n",
    "\n",
    "print(\"Proses persiapan corpus selesai.\")\n",
    "print(\"Berikut adalah contoh 1 abstrak yang sudah diubah menjadi daftar token:\")\n",
    "print(corpus[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bcb5d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 03:10:48,174 : INFO : collecting all words and their counts\n",
      "2025-10-02 03:10:48,175 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2025-10-02 03:10:48,196 : INFO : collected 6498 word types from a corpus of 148249 raw words and 1026 sentences\n",
      "2025-10-02 03:10:48,196 : INFO : Creating a fresh vocabulary\n",
      "2025-10-02 03:10:48,202 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 3544 unique words (54.54% of original 6498, drops 2954)', 'datetime': '2025-10-02T03:10:48.202165', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2025-10-02 03:10:48,203 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 145295 word corpus (98.01% of original 148249, drops 2954)', 'datetime': '2025-10-02T03:10:48.203167', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2025-10-02 03:10:48,219 : INFO : deleting the raw counts dictionary of 6498 items\n",
      "2025-10-02 03:10:48,220 : INFO : sample=0.001 downsamples 67 most-common words\n",
      "2025-10-02 03:10:48,222 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 108970.73386089882 word corpus (75.0%% of prior 145295)', 'datetime': '2025-10-02T03:10:48.222288', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2025-10-02 03:10:48,242 : INFO : estimated required memory for 3544 words and 150 dimensions: 6024800 bytes\n",
      "2025-10-02 03:10:48,243 : INFO : resetting layer weights\n",
      "2025-10-02 03:10:48,246 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-10-02T03:10:48.246112', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "2025-10-02 03:10:48,247 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 3544 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-10-02T03:10:48.247115', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'train'}\n",
      "2025-10-02 03:10:48,318 : INFO : EPOCH 0: training on 148249 raw words (108963 effective words) took 0.1s, 1597574 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 2: MELATIH MODEL WORD2VEC (CBOW) ---\n",
      "Parameter: Dimensi vektor = 150, Arsitektur = CBOW\n",
      "Gensim akan menampilkan log proses training di bawah ini:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 03:10:48,369 : INFO : EPOCH 1: training on 148249 raw words (108926 effective words) took 0.0s, 2299137 effective words/s\n",
      "2025-10-02 03:10:48,422 : INFO : EPOCH 2: training on 148249 raw words (108936 effective words) took 0.1s, 2122574 effective words/s\n",
      "2025-10-02 03:10:48,483 : INFO : EPOCH 3: training on 148249 raw words (109149 effective words) took 0.1s, 1854440 effective words/s\n",
      "2025-10-02 03:10:48,541 : INFO : EPOCH 4: training on 148249 raw words (108947 effective words) took 0.1s, 1967092 effective words/s\n",
      "2025-10-02 03:10:48,542 : INFO : Word2Vec lifecycle event {'msg': 'training on 741245 raw words (544921 effective words) took 0.3s, 1855284 effective words/s', 'datetime': '2025-10-02T03:10:48.542014', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'train'}\n",
      "2025-10-02 03:10:48,542 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=3544, vector_size=150, alpha=0.025>', 'datetime': '2025-10-02T03:10:48.542704', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pelatihan model selesai!\n",
      "\n",
      "--- Melihat Hasil Pelatihan Model ---\n",
      "Model berhasil mempelajari 3544 kata unik.\n",
      "\n",
      "Contoh kata yang paling mirip dengan 'pengaruh':\n",
      "[('biologis', 0.9279569983482361), ('bersamasama', 0.9224080443382263), ('domian', 0.906585693359375), ('positif', 0.8981070518493652), ('signifikan', 0.8956397771835327)]\n",
      "\n",
      "Contoh kata yang paling mirip dengan 'kinerja':\n",
      "\n",
      "Kata \"Key 'kinerja' not present in vocabulary\" tidak ditemukan di vocabulary (mungkin karena jarang muncul).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2. Melatih Model Word2Vec (dengan Proses Terlihat) ---\n",
    "print(\"--- TAHAP 2: MELATIH MODEL WORD2VEC (CBOW) ---\")\n",
    "\n",
    "# Mengaktifkan logging untuk melihat proses training dari Gensim\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Tentukan parameter model. Anda bisa mengubah nilai embedding_dim.\n",
    "embedding_dim = 150 \n",
    "print(f\"Parameter: Dimensi vektor = {embedding_dim}, Arsitektur = CBOW\")\n",
    "print(\"Gensim akan menampilkan log proses training di bawah ini:\")\n",
    "\n",
    "model_cbow = Word2Vec(\n",
    "    sentences=corpus,\n",
    "    vector_size=embedding_dim,\n",
    "    window=5,\n",
    "    min_count=2, # Mengabaikan kata yang muncul kurang dari 2 kali\n",
    "    sg=0,        # sg=0 untuk arsitektur CBOW\n",
    "    workers=4    # Memanfaatkan beberapa core CPU\n",
    ")\n",
    "\n",
    "print(\"\\nPelatihan model selesai!\")\n",
    "print(\"\\n--- Melihat Hasil Pelatihan Model ---\")\n",
    "# Mengetahui ukuran kosakata yang berhasil dipelajari model\n",
    "vocab_size = len(model_cbow.wv.index_to_key)\n",
    "print(f\"Model berhasil mempelajari {vocab_size} kata unik.\")\n",
    "\n",
    "# Melihat kata-kata yang paling mirip secara semantik\n",
    "# Ini membuktikan model sudah belajar konteks dari data abstrak manajemen\n",
    "try:\n",
    "    print(\"\\nContoh kata yang paling mirip dengan 'pengaruh':\")\n",
    "    print(model_cbow.wv.most_similar('pengaruh', topn=5))\n",
    "\n",
    "    print(\"\\nContoh kata yang paling mirip dengan 'kinerja':\")\n",
    "    print(model_cbow.wv.most_similar('kinerja', topn=5))\n",
    "except KeyError as e:\n",
    "    print(f\"\\nKata {e} tidak ditemukan di vocabulary (mungkin karena jarang muncul).\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "514f99a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 3: MEMBEDAH PROSES AGREGRASI MENJADI VEKTOR DOKUMEN ---\n",
      "Kita akan menganalisis abstrak pertama:\n",
      "Isi abstrak (token): ['abstrak', 'satiyah', 'pengaruh', 'faktorfaktor', 'latih', 'kembang', 'produktivitas', 'kerja', 'dinas', 'laut', 'ikan', 'bangkal', 'bawah', 'bimbing', 'drahjsanugrahini', 'irawatimm', 'helm', 'buyung', 'auliasstsemmt', 'upaya']...\n",
      "\n",
      "Vektor untuk 3 kata pertama dalam abstrak:\n",
      "  - Vektor kata 'abstrak': [ 0.3088086   0.23151623  0.05812349  0.29459843 -0.3425866 ]...\n",
      "  - Kata 'satiyah' tidak ada di vocabulary model.\n",
      "  - Vektor kata 'pengaruh': [ 0.27310506  0.19581613  0.4184652   0.2810729  -0.7425907 ]...\n",
      "\n",
      "Hasil vektor dokumen (setelah dirata-ratakan):\n",
      "[ 0.03525675 -0.00926918  0.04646508 -0.0857008  -0.40204543 -0.1869668\n",
      "  0.02401656  0.06331303 -0.29669097  0.05296404]...\n",
      "Panjang vektor: 150 dimensi.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. Membedah Proses Agregasi Vektor Dokumen ---\n",
    "print(\"--- TAHAP 3: MEMBEDAH PROSES AGREGRASI MENJADI VEKTOR DOKUMEN ---\")\n",
    "\n",
    "def create_document_vector(doc, model, num_features):\n",
    "    word_vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(num_features)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Mari kita ambil satu abstrak sebagai contoh\n",
    "contoh_abstrak = corpus[0]\n",
    "print(\"Kita akan menganalisis abstrak pertama:\")\n",
    "print(f\"Isi abstrak (token): {contoh_abstrak[:20]}...\") # Tampilkan 20 token pertama\n",
    "\n",
    "# Melihat vektor dari beberapa kata pertama di abstrak tersebut\n",
    "print(\"\\nVektor untuk 3 kata pertama dalam abstrak:\")\n",
    "for word in contoh_abstrak[:3]:\n",
    "    if word in model_cbow.wv:\n",
    "        print(f\"  - Vektor kata '{word}': {model_cbow.wv[word][:5]}...\")\n",
    "    else:\n",
    "        print(f\"  - Kata '{word}' tidak ada di vocabulary model.\")\n",
    "\n",
    "# Menghitung dan menampilkan vektor akhir untuk abstrak tersebut\n",
    "vektor_abstrak_contoh = create_document_vector(contoh_abstrak, model_cbow, embedding_dim)\n",
    "print(\"\\nHasil vektor dokumen (setelah dirata-ratakan):\")\n",
    "print(f\"{vektor_abstrak_contoh[:10]}...\")\n",
    "print(f\"Panjang vektor: {len(vektor_abstrak_contoh)} dimensi.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cbcb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 4: MEMBUAT DATAFRAME AKHIR ---\n",
      "Proses pembuatan DataFrame selesai.\n",
      "Berikut adalah contoh hasil akhirnya:\n",
      "      dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
      "0  0.035257 -0.009269  0.046465 -0.085701 -0.402045 -0.186967  0.024017   \n",
      "1  0.020515  0.368966 -0.199549 -0.424640 -0.249926 -0.414181  0.030686   \n",
      "2  0.079249  0.207760 -0.187530 -0.183840 -0.274609 -0.242842  0.093370   \n",
      "3 -0.087995  0.245899  0.151830 -0.123538 -0.582350 -0.096582 -0.098186   \n",
      "4 -0.024200  0.261841 -0.029502 -0.154847 -0.457773 -0.192367 -0.041937   \n",
      "\n",
      "      dim_8     dim_9    dim_10  ...   dim_142   dim_143   dim_144   dim_145  \\\n",
      "0  0.063313 -0.296691  0.052964  ... -0.143811  0.239018  0.120713  0.320310   \n",
      "1  0.253525 -0.338312 -0.118808  ... -0.180525  0.040859  0.430816  0.199846   \n",
      "2  0.250218 -0.266122 -0.069349  ... -0.217033  0.106149  0.253803  0.239334   \n",
      "3 -0.061739 -0.366246 -0.144256  ... -0.120296  0.185006  0.111743  0.313776   \n",
      "4  0.152182 -0.313905 -0.031930  ... -0.168150  0.077601  0.244204  0.292630   \n",
      "\n",
      "    dim_146   dim_147   dim_148   dim_149   dim_150  \\\n",
      "0  0.015517 -0.291727 -0.201869  0.673097 -0.296410   \n",
      "1  0.113625 -0.187243 -0.221657  0.476612 -0.193972   \n",
      "2  0.060614 -0.098944 -0.091900  0.384870 -0.208265   \n",
      "3  0.109383 -0.230134 -0.491946  0.780402 -0.507965   \n",
      "4  0.021189 -0.189705 -0.246816  0.615455 -0.467579   \n",
      "\n",
      "                                          abstrak_id  \n",
      "0  ABSTRAK\\r\\nSatiyah, Pengaruh Faktor-faktor Pel...  \n",
      "1  Tujuan penelitian ini adalah untuk mengetahui ...  \n",
      "2  Aplikasi nyata pemanfaatan teknologi informasi...  \n",
      "3  Abstrak\\r\\nPenelitian ini menggunakan metode k...  \n",
      "4  Abstrak\\r\\n\\r\\nAththaariq, Pengaruh Kompetensi...  \n",
      "\n",
      "[5 rows x 151 columns]\n",
      "\n",
      "ðŸŽ‰ Hasil CBOW berhasil disimpan ke file: hasil_cbow_pta_manajemen.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- 4. Membuat DataFrame Akhir ---\n",
    "print(\"--- TAHAP 4: MEMBUAT DATAFRAME AKHIR ---\")\n",
    "doc_vectors = [create_document_vector(doc, model_cbow, embedding_dim) for doc in corpus]\n",
    "cbow_df = pd.DataFrame(doc_vectors, columns=[f'dim_{i+1}' for i in range(embedding_dim)])\n",
    "# Menambahkan kembali kolom abstrak_id agar sesuai dengan file TF-IDF\n",
    "cbow_df['abstrak_id'] = df['abstrak_id'].values \n",
    "\n",
    "print(\"Proses pembuatan DataFrame selesai.\")\n",
    "print(\"Berikut adalah contoh hasil akhirnya:\")\n",
    "print(cbow_df.head())\n",
    "\n",
    "# Menyimpan hasil ke file CSV\n",
    "output_file_cbow = \"hasil_cbow_pta_manajemen.csv\"\n",
    "cbow_df.to_csv(output_file_cbow, index=False)\n",
    "print(f\"\\nðŸŽ‰ Hasil CBOW berhasil disimpan ke file: {output_file_cbow}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
