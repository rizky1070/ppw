{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e5a919",
   "metadata": {},
   "source": [
    "# CBOW PTA Manajemen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c044a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 1: MEMPERSIAPKAN CORPUS ---\n",
      "Proses persiapan corpus selesai.\n",
      "Berikut adalah contoh 1 abstrak yang sudah diubah menjadi daftar token:\n",
      "['satiyah', 'pengaruh', 'faktorfaktor', 'latih', 'kembang', 'produktivitas', 'kerja', 'dinas', 'laut', 'ikan', 'bangkal', 'bawah', 'bimbing', 'drahjsanugrahini', 'irawatimm', 'helm', 'buyung', 'auliasstsemmt', 'upaya', 'tingkat', 'produktivitas', 'kerja', 'mudah', 'salah', 'usaha', 'produktivitas', 'tingkat', 'terap', 'program', 'latih', 'kembang', 'sumber', 'daya', 'manusia', 'sdm', 'laksana', 'instansi', 'produktivitas', 'capai', 'tingkat', 'mampu', 'pegawai', 'efektif', 'efisien', 'latih', 'pengembnagan', 'harap', 'pegawai', 'sesuai', 'kebutuhankebutuhan', 'sikap', 'tingkah', 'laku', 'terampil', 'tahu', 'sesuai', 'tuntut', 'ubah', 'latih', 'kembang', 'pegawai', 'dukung', 'cipta', 'suasana', 'kerja', 'kondusif', 'instansi', 'produktivitas', 'kerja', 'tingkat', 'tuju', 'teliti', 'pengaruh', 'faktorfaktor', 'latih', 'kembang', 'produktivitas', 'kerja', 'dinas', 'laut', 'ikan', 'bangkal', 'ukur', 'menganalisa', 'hubung', 'variabel', 'teliti', 'dekat', 'observasional', 'analitik', 'amat', 'langsung', 'responden', 'sebar', 'kuisioner', 'analis', 'teliti', 'teliti', 'populasi', 'responden', 'sampel', 'olah', 'spss', 'versi', 'analis', 'metode', 'statistik', 'metode', 'non', 'probality', 'sampling', 'simple', 'random', 'sampling', 'simpul', 'teliti', 'a', 'faktorfaktor', 'latih', 'kembang', 'beda', 'individu', 'pegawai', 'x', 'hubung', 'analisis', 'jabat', 'x', 'motivasi', 'x', 'partisipasi', 'aktif', 'x', 'seleksi', 'serta', 'x', 'seleksi', 'instruktur', 'x', 'metode', 'latih', 'kembang', 'x', 'pengaruh', 'simultan', 'produktivitas', 'kerja', 'pegawai', 'dinas', 'laut', 'ikan', 'kabupaten', 'bangkal', 'bukti', 'nilai', 'koefisien', 'determinasi', 'ganda', 'r', 'r', 'square', 'fhitung', 'ftabel', 'b', 'faktor', 'hubung', 'analisis', 'jabat', 'pengaruh', 'parsial', 'produktivitas', 'kerja', 'pegawai', 'dinas', 'laut', 'ikan', 'kabupaten', 'bangkal', 'uji', 'hipotesis', 'variabel', 'motivasi', 'x', 'bukti', 'nilai', 'thitung', 'seleksi', 'serta', 'x', 'pengaruh', 'dominan', 'produktivitas', 'kerja', 'pegawai', 'instansi', 'dinas', 'laut', 'ikan', 'bangkal', 'kunci', 'dinas', 'laut', 'ikan', 'faktorfaktor', 'latih', 'kembang', 'produktivitas', 'kerja']\n"
     ]
    }
   ],
   "source": [
    "# --- Import semua library yang dibutuhkan ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from gensim.models import Word2Vec\n",
    "import logging # Untuk menampilkan log proses training\n",
    "\n",
    "# --- 1. Persiapan Corpus ---\n",
    "print(\"--- TAHAP 1: MEMPERSIAPKAN CORPUS ---\")\n",
    "# Load data dari file CSV hasil preprocessing Anda\n",
    "df = pd.read_csv('hasil_preprocessing_manajemen.csv')\n",
    "\n",
    "# Mengubah kolom 'hasil_preprocessing' dari string menjadi list python sungguhan\n",
    "df['tokens'] = df['hasil_preprocessing'].apply(ast.literal_eval)\n",
    "corpus = df['tokens'].tolist()\n",
    "\n",
    "print(\"Proses persiapan corpus selesai.\")\n",
    "print(\"Berikut adalah contoh 1 abstrak yang sudah diubah menjadi daftar token:\")\n",
    "print(corpus[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bcb5d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 11:57:43,812 : INFO : collecting all words and their counts\n",
      "2025-10-10 11:57:43,813 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2025-10-10 11:57:43,828 : INFO : collected 6497 word types from a corpus of 147875 raw words and 1026 sentences\n",
      "2025-10-10 11:57:43,829 : INFO : Creating a fresh vocabulary\n",
      "2025-10-10 11:57:43,840 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 3543 unique words (54.53% of original 6497, drops 2954)', 'datetime': '2025-10-10T11:57:43.840612', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2025-10-10 11:57:43,841 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 144921 word corpus (98.00% of original 147875, drops 2954)', 'datetime': '2025-10-10T11:57:43.841614', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2025-10-10 11:57:43,855 : INFO : deleting the raw counts dictionary of 6497 items\n",
      "2025-10-10 11:57:43,856 : INFO : sample=0.001 downsamples 67 most-common words\n",
      "2025-10-10 11:57:43,857 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 108540.54174002048 word corpus (74.9%% of prior 144921)', 'datetime': '2025-10-10T11:57:43.857612', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "2025-10-10 11:57:43,883 : INFO : estimated required memory for 3543 words and 150 dimensions: 6023100 bytes\n",
      "2025-10-10 11:57:43,884 : INFO : resetting layer weights\n",
      "2025-10-10 11:57:43,887 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-10-10T11:57:43.887612', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "2025-10-10 11:57:43,887 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 3543 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-10-10T11:57:43.887612', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'train'}\n",
      "2025-10-10 11:57:43,950 : INFO : EPOCH 0: training on 147875 raw words (108461 effective words) took 0.1s, 1853258 effective words/s\n",
      "2025-10-10 11:57:44,018 : INFO : EPOCH 1: training on 147875 raw words (108541 effective words) took 0.1s, 1711059 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 2: MELATIH MODEL WORD2VEC (CBOW) ---\n",
      "Parameter: Dimensi vektor = 150, Arsitektur = CBOW\n",
      "Gensim akan menampilkan log proses training di bawah ini:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 11:57:44,083 : INFO : EPOCH 2: training on 147875 raw words (108435 effective words) took 0.1s, 1754271 effective words/s\n",
      "2025-10-10 11:57:44,147 : INFO : EPOCH 3: training on 147875 raw words (108366 effective words) took 0.1s, 1796203 effective words/s\n",
      "2025-10-10 11:57:44,213 : INFO : EPOCH 4: training on 147875 raw words (108622 effective words) took 0.1s, 1719306 effective words/s\n",
      "2025-10-10 11:57:44,214 : INFO : Word2Vec lifecycle event {'msg': 'training on 739375 raw words (542425 effective words) took 0.3s, 1664703 effective words/s', 'datetime': '2025-10-10T11:57:44.214613', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'train'}\n",
      "2025-10-10 11:57:44,214 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=3543, vector_size=150, alpha=0.025>', 'datetime': '2025-10-10T11:57:44.214613', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pelatihan model selesai!\n",
      "\n",
      "--- Melihat Hasil Pelatihan Model ---\n",
      "Model berhasil mempelajari 3543 kata unik.\n",
      "\n",
      "Contoh kata yang paling mirip dengan 'pengaruh':\n",
      "[('bersamasama', 0.9194615483283997), ('positif', 0.9171957969665527), ('signifikan', 0.9135518074035645), ('biologis', 0.9096216559410095), ('fisik', 0.8896639347076416)]\n",
      "\n",
      "Contoh kata yang paling mirip dengan 'kinerja':\n",
      "\n",
      "Kata \"Key 'kinerja' not present in vocabulary\" tidak ditemukan di vocabulary (mungkin karena jarang muncul).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2. Melatih Model Word2Vec (dengan Proses Terlihat) ---\n",
    "print(\"--- TAHAP 2: MELATIH MODEL WORD2VEC (CBOW) ---\")\n",
    "\n",
    "# Mengaktifkan logging untuk melihat proses training dari Gensim\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Tentukan parameter model. Anda bisa mengubah nilai embedding_dim.\n",
    "embedding_dim = 150 \n",
    "print(f\"Parameter: Dimensi vektor = {embedding_dim}, Arsitektur = CBOW\")\n",
    "print(\"Gensim akan menampilkan log proses training di bawah ini:\")\n",
    "\n",
    "model_cbow = Word2Vec(\n",
    "    sentences=corpus,\n",
    "    vector_size=embedding_dim,\n",
    "    window=5,\n",
    "    min_count=2, # Mengabaikan kata yang muncul kurang dari 2 kali\n",
    "    sg=0,        # sg=0 untuk arsitektur CBOW\n",
    "    workers=4    # Memanfaatkan beberapa core CPU\n",
    ")\n",
    "\n",
    "print(\"\\nPelatihan model selesai!\")\n",
    "print(\"\\n--- Melihat Hasil Pelatihan Model ---\")\n",
    "# Mengetahui ukuran kosakata yang berhasil dipelajari model\n",
    "vocab_size = len(model_cbow.wv.index_to_key)\n",
    "print(f\"Model berhasil mempelajari {vocab_size} kata unik.\")\n",
    "\n",
    "# Melihat kata-kata yang paling mirip secara semantik\n",
    "# Ini membuktikan model sudah belajar konteks dari data abstrak manajemen\n",
    "try:\n",
    "    print(\"\\nContoh kata yang paling mirip dengan 'pengaruh':\")\n",
    "    print(model_cbow.wv.most_similar('pengaruh', topn=5))\n",
    "\n",
    "    print(\"\\nContoh kata yang paling mirip dengan 'kinerja':\")\n",
    "    print(model_cbow.wv.most_similar('kinerja', topn=5))\n",
    "except KeyError as e:\n",
    "    print(f\"\\nKata {e} tidak ditemukan di vocabulary (mungkin karena jarang muncul).\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "514f99a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 3: MEMBEDAH PROSES AGREGRASI MENJADI VEKTOR DOKUMEN ---\n",
      "Kita akan menganalisis abstrak pertama:\n",
      "Isi abstrak (token): ['satiyah', 'pengaruh', 'faktorfaktor', 'latih', 'kembang', 'produktivitas', 'kerja', 'dinas', 'laut', 'ikan', 'bangkal', 'bawah', 'bimbing', 'drahjsanugrahini', 'irawatimm', 'helm', 'buyung', 'auliasstsemmt', 'upaya', 'tingkat']...\n",
      "\n",
      "Vektor untuk 3 kata pertama dalam abstrak:\n",
      "  - Kata 'satiyah' tidak ada di vocabulary model.\n",
      "  - Vektor kata 'pengaruh': [ 0.007376    0.48185635  0.34049368  0.3876823  -0.6183384 ]...\n",
      "  - Vektor kata 'faktorfaktor': [ 0.072497   -0.07759781  0.06355953  0.07517678 -0.09688607]...\n",
      "\n",
      "Hasil vektor dokumen (setelah dirata-ratakan):\n",
      "[-0.0087224  -0.1393054   0.11421116  0.01019875 -0.1793711  -0.55266595\n",
      "  0.03153921  0.29816124 -0.3023719   0.22631276]...\n",
      "Panjang vektor: 150 dimensi.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. Membedah Proses Agregasi Vektor Dokumen ---\n",
    "print(\"--- TAHAP 3: MEMBEDAH PROSES AGREGRASI MENJADI VEKTOR DOKUMEN ---\")\n",
    "\n",
    "def create_document_vector(doc, model, num_features):\n",
    "    word_vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(num_features)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Mari kita ambil satu abstrak sebagai contoh\n",
    "contoh_abstrak = corpus[0]\n",
    "print(\"Kita akan menganalisis abstrak pertama:\")\n",
    "print(f\"Isi abstrak (token): {contoh_abstrak[:20]}...\") # Tampilkan 20 token pertama\n",
    "\n",
    "# Melihat vektor dari beberapa kata pertama di abstrak tersebut\n",
    "print(\"\\nVektor untuk 3 kata pertama dalam abstrak:\")\n",
    "for word in contoh_abstrak[:3]:\n",
    "    if word in model_cbow.wv:\n",
    "        print(f\"  - Vektor kata '{word}': {model_cbow.wv[word][:5]}...\")\n",
    "    else:\n",
    "        print(f\"  - Kata '{word}' tidak ada di vocabulary model.\")\n",
    "\n",
    "# Menghitung dan menampilkan vektor akhir untuk abstrak tersebut\n",
    "vektor_abstrak_contoh = create_document_vector(contoh_abstrak, model_cbow, embedding_dim)\n",
    "print(\"\\nHasil vektor dokumen (setelah dirata-ratakan):\")\n",
    "print(f\"{vektor_abstrak_contoh[:10]}...\")\n",
    "print(f\"Panjang vektor: {len(vektor_abstrak_contoh)} dimensi.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40cbcb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TAHAP 4: MEMBUAT DATAFRAME AKHIR ---\n",
      "Proses pembuatan DataFrame selesai.\n",
      "Berikut adalah contoh hasil akhirnya:\n",
      "      dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
      "0 -0.008722 -0.139305  0.114211  0.010199 -0.179371 -0.552666  0.031539   \n",
      "1 -0.066206 -0.086278 -0.353659 -0.141009 -0.070566 -0.400461 -0.152536   \n",
      "2  0.030354 -0.113717 -0.167099 -0.008595 -0.150836 -0.340072  0.002448   \n",
      "3 -0.191087  0.122379  0.143438  0.100596 -0.383331 -0.730081 -0.161397   \n",
      "4 -0.111101 -0.027134 -0.027297  0.077395 -0.274000 -0.527025 -0.143541   \n",
      "\n",
      "      dim_8     dim_9    dim_10  ...   dim_142   dim_143   dim_144   dim_145  \\\n",
      "0  0.298161 -0.302372  0.226313  ... -0.094864 -0.046029  0.111178  0.319279   \n",
      "1  0.494331 -0.172244  0.040324  ... -0.264218 -0.106688  0.465472  0.233445   \n",
      "2  0.388654 -0.089782  0.210331  ... -0.190525 -0.044635  0.198831  0.171288   \n",
      "3  0.228955 -0.623756  0.005552  ... -0.095379 -0.240097 -0.019884  0.367287   \n",
      "4  0.398703 -0.347684  0.157270  ... -0.201208 -0.223871  0.148042  0.273393   \n",
      "\n",
      "    dim_146   dim_147   dim_148   dim_149   dim_150  \\\n",
      "0 -0.088156 -0.291654 -0.126327  0.426726  0.060698   \n",
      "1 -0.276515 -0.220921 -0.218625  0.209549 -0.131537   \n",
      "2 -0.179987 -0.152578 -0.151507  0.274098 -0.141860   \n",
      "3 -0.125824 -0.369266 -0.272664  0.462628  0.191164   \n",
      "4 -0.157726 -0.331822 -0.179000  0.434731 -0.019438   \n",
      "\n",
      "                                          abstrak_id  \n",
      "0  ABSTRAK\\r\\nSatiyah, Pengaruh Faktor-faktor Pel...  \n",
      "1  Tujuan penelitian ini adalah untuk mengetahui ...  \n",
      "2  Aplikasi nyata pemanfaatan teknologi informasi...  \n",
      "3  Abstrak\\r\\nPenelitian ini menggunakan metode k...  \n",
      "4  Abstrak\\r\\n\\r\\nAththaariq, Pengaruh Kompetensi...  \n",
      "\n",
      "[5 rows x 151 columns]\n",
      "\n",
      "ðŸŽ‰ Hasil CBOW berhasil disimpan ke file: hasil_cbow_pta_manajemen.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Membuat DataFrame Akhir ---\n",
    "print(\"--- TAHAP 4: MEMBUAT DATAFRAME AKHIR ---\")\n",
    "doc_vectors = [create_document_vector(doc, model_cbow, embedding_dim) for doc in corpus]\n",
    "cbow_df = pd.DataFrame(doc_vectors, columns=[f'dim_{i+1}' for i in range(embedding_dim)])\n",
    "# Menambahkan kembali kolom abstrak_id agar sesuai dengan file TF-IDF\n",
    "cbow_df['abstrak_id'] = df['abstrak_id'].values \n",
    "\n",
    "print(\"Proses pembuatan DataFrame selesai.\")\n",
    "print(\"Berikut adalah contoh hasil akhirnya:\")\n",
    "print(cbow_df.head())\n",
    "\n",
    "# Menyimpan hasil ke file CSV\n",
    "output_file_cbow = \"hasil_cbow_pta_manajemen.csv\"\n",
    "cbow_df.to_csv(output_file_cbow, index=False)\n",
    "print(f\"\\nðŸŽ‰ Hasil CBOW berhasil disimpan ke file: {output_file_cbow}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
